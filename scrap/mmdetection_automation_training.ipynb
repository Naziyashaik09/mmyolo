{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f455b84-3f4b-4f22-aa23-ad532b7d11e1",
   "metadata": {},
   "source": [
    "# Enter the dataset paths , the percentage for the data split and the parameters to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead2554-8922-48af-bc3d-ef16d064d215",
   "metadata": {},
   "source": [
    "### Before starting , once refer the readme.md file in the location \"/home/viso/sample_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c216133-47ec-4356-8da3-e8e9ea85bf4a",
   "metadata": {},
   "source": [
    "# If you want to download the predefined dataset follow the next 2 steps or else you can skip that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9926dcf7-c75a-4f08-a0d0-c0c0df58faa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://download.openmmlab.com/mmyolo/data/cat_dataset.zip to data/cat/cat_dataset.zip\n",
      "100%|████████████████████████████████████████| 217M/217M [00:22<00:00, 10.2MB/s]\n",
      "Unzipping cat_dataset.zip\n",
      "Delete data/cat/cat_dataset.zip\n"
     ]
    }
   ],
   "source": [
    "!python3 tools/misc/download_dataset.py --dataset-name cat --save-dir ./data/cat --unzip --delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d6468b-8da5-4d58-8ef8-37d0c4e216c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations_all.json  test.json   trainval.json\n",
      "output_json.json      train.json  val.json\n"
     ]
    }
   ],
   "source": [
    "ls data/cat/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d982c8df-5521-4ff2-9319-2f076e1d4665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/workspace/mmyolo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86f2872-a88c-40c6-beab-672c0ea28dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the dataset root path /root/workspace/mmyolo/data/cat\n",
      "Enter the annotation path ,(json file) /root/workspace/mmyolo/data/cat/annotations/annotations_all.json\n",
      "Enter the percentage to divide the train dataset. Eg:0.8 0.8\n",
      "Enter the percentage to divide the test dataset. Eg:0.1 0.1\n",
      "Enter the percentage to divide the validation dataset. Eg:0.1 0.1\n",
      "Enter the MAX_EPOCHS  100\n",
      "Enter the BATCH_SIZE 4\n"
     ]
    }
   ],
   "source": [
    "# dataset_root is the path , where images and the annotation file consists \n",
    "dataset_root=input('Enter the dataset root path')\n",
    "\n",
    "# annotation_path , where there is a single file annotation in the coco (json) format \n",
    "annotation_path=input('Enter the annotation path ,(json file)')\n",
    "\n",
    "# consists of images for training\n",
    "train_percentage=input('Enter the percentage to divide the train dataset. Eg:0.8')\n",
    "test_percentage= input('Enter the percentage to divide the test dataset. Eg:0.1')\n",
    "val_percentage= input('Enter the percentage to divide the validation dataset. Eg:0.1')\n",
    "\n",
    "# enter the epochs , upto how much epochs the models needs to train \n",
    "MAX_EPOCHS = input('Enter the MAX_EPOCHS ')\n",
    "\n",
    "# BATCH_SIZE means  \"The number of training examples utilized in one iteration\".\n",
    "BATCH_SIZE = input('Enter the BATCH_SIZE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6373b-a8bb-4491-a1c4-74bc87e31066",
   "metadata": {},
   "source": [
    "# select the model , need to do testing and quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd517055-1ef9-4450-b532-87017dea5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a model type:\n",
      "0. YOLOx\n",
      "1. RTMDET\n",
      "2. YOLOv7\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (0-2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a RTMDET model variant:\n",
      "0. rtmdet_tiny\n",
      "1. rtmdet_s\n",
      "2. rtmdet_l\n",
      "3. rtmdet_m\n",
      "4. rtmdet_x\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (0-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected: rtmdet_m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to train the model with data augmentation? (0 for no, 1 for yes):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify whether you want to enable or disable each augmentation option (0 for False, 1 for True):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to enable Noise? (0 for False, 1 for True):  1\n",
      "Do you want to enable Denoise? (0 for False, 1 for True):  0\n",
      "Do you want to enable Contrast? (0 for False, 1 for True):  1\n",
      "Do you want to enable Brightness? (0 for False, 1 for True):  1\n",
      "Do you want to enable Rotation? (0 for False, 1 for True):  1\n",
      "Do you need to test? (0 for no, 1 for yes):  1\n",
      "Do you want to test on an image or a video? (0 for image, 1 for video):  0\n",
      "Do you want to quantize the model? (0 for no, 1 for yes):  1\n",
      "Choose quantization precision (0 for fp16, 1 for fp32):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose batch size:\n",
      "0. 1\n",
      "1. 2\n",
      "2. 4\n",
      "3. 8\n",
      "4. 16\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (0-4):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected: rtmdet_m\n",
      "Testing option: yes\n",
      "Testing on: image at path: \n",
      "Quantize option: yes\n",
      "Quantization precision: fp32\n",
      "Batch size: 8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Dictionary of model types and their corresponding options\n",
    "model_types = {\n",
    "    \"YOLOx\": [\"yolox_tiny\", \"yolox_s\", \"yolox_m\", \"yolox_l\", \"yolox_x\"],\n",
    "    \"RTMDET\": [\"rtmdet_tiny\", \"rtmdet_s\", \"rtmdet_l\", \"rtmdet_m\", \"rtmdet_x\"],\n",
    "    \"YOLOv7\": [\"yolov7_tiny\", \"yolov7_l\", \"yolov7_x\", \"yolov7_w\", \"yolov7_e\"],\n",
    "}\n",
    "\n",
    "# Batch size options\n",
    "batch_size_options = [1, 2, 4, 8, 16]\n",
    "\n",
    "# Variable to store user's choice\n",
    "selected_model_type = None\n",
    "selected_model_variant = None\n",
    "test_option = None\n",
    "path = None\n",
    "quantize_option = None\n",
    "quantize_bits = None\n",
    "batch_size = None\n",
    "AUGMENTATIONS = {\n",
    "    \"noise\": False,\n",
    "    \"denoise\": False,\n",
    "    \"contrast\": False,\n",
    "    \"brightness\": False,\n",
    "    \"rotation\": False\n",
    "}\n",
    "# Print model types\n",
    "print(\"Please select a model type:\")\n",
    "for i, model_type in enumerate(model_types):\n",
    "    print(f\"{i}. {model_type}\")\n",
    "\n",
    "# Get input for model type\n",
    "while True:\n",
    "    model_type_choice = input(\"Enter choice (0-{}): \".format(len(model_types) - 1))\n",
    "    try:\n",
    "        model_type_choice = int(model_type_choice)\n",
    "        if 0 <= model_type_choice < len(model_types):\n",
    "            selected_model_type = list(model_types.keys())[model_type_choice]\n",
    "            break\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    print(\"Invalid choice, please try again\")\n",
    "\n",
    "# Print model variants for the selected model type\n",
    "print(f\"Please select a {selected_model_type} model variant:\")\n",
    "for i, model_variant in enumerate(model_types[selected_model_type]):\n",
    "    print(f\"{i}. {model_variant}\")\n",
    "\n",
    "# Get input for model variant\n",
    "while True:\n",
    "    model_variant_choice = input(\"Enter choice (0-{}): \".format(len(model_types[selected_model_type]) - 1))\n",
    "    try:\n",
    "        model_variant_choice = int(model_variant_choice)\n",
    "        if 0 <= model_variant_choice < len(model_types[selected_model_type]):\n",
    "            selected_model_variant = model_types[selected_model_type][model_variant_choice]\n",
    "            break\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    print(\"Invalid choice, please try again\")\n",
    "\n",
    "print(f\"You selected: {selected_model_variant}\")\n",
    "# Ask if the user wants to train the model with data augmentation\n",
    "while True:\n",
    "    train_with_augmentation = input(\"Do you want to train the model with data augmentation? (0 for no, 1 for yes): \")\n",
    "    if train_with_augmentation in [\"0\", \"1\"]:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "if train_with_augmentation == \"1\":\n",
    "    print(\"Please specify whether you want to enable or disable each augmentation option (0 for False, 1 for True):\")\n",
    "    for augmentation, enabled in AUGMENTATIONS.items():\n",
    "        while True:\n",
    "            choice = input(f\"Do you want to enable {augmentation.capitalize()}? (0 for False, 1 for True): \")\n",
    "            if choice in [\"0\", \"1\"]:\n",
    "                AUGMENTATIONS[augmentation] = choice == \"1\"\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "# Ask if the user wants to test\n",
    "while True:\n",
    "    test_option = input(\"Do you need to test? (0 for no, 1 for yes): \")\n",
    "    if test_option in [\"0\", \"1\"]:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "\n",
    "# If testing is required, ask for image or video and corresponding path\n",
    "if test_option == \"1\":\n",
    "    while True:\n",
    "        test_type = input(\"Do you want to test on an image or a video? (0 for image, 1 for video): \")\n",
    "        if test_type == \"0\":\n",
    "            path = ''  # You can set a default value or leave it empty for images\n",
    "            break\n",
    "        elif test_type == \"1\":\n",
    "            video_path = input(\"Enter the video path: \")\n",
    "            output_path = input(\"Enter the path to save the video: \")\n",
    "\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "\n",
    "# Now 'path' will be either an empty string for images or the user-provided video path for videos\n",
    "\n",
    "# Ask if the user wants to quantize the model\n",
    "while True:\n",
    "    quantize_option = input(\"Do you want to quantize the model? (0 for no, 1 for yes): \")\n",
    "    if quantize_option in [\"0\", \"1\"]:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "\n",
    "# If quantizing is required, ask for the quantization bit precision\n",
    "if quantize_option == \"1\":\n",
    "    while True:\n",
    "        quantize_bits = input(\"Choose quantization precision (0 for fp16, 1 for fp32): \")\n",
    "        if quantize_bits in [\"0\", \"1\"]:\n",
    "            if quantize_bits == \"0\" or quantize_bits == \"1\":\n",
    "                while True:\n",
    "                    print(\"Choose batch size:\")\n",
    "                    for i, size in enumerate(batch_size_options):\n",
    "                        print(f\"{i}. {size}\")\n",
    "\n",
    "                    batch_size_choice = input(\"Enter choice (0-{}): \".format(len(batch_size_options) - 1))\n",
    "                    try:\n",
    "                        batch_size_choice = int(batch_size_choice)\n",
    "                        if 0 <= batch_size_choice < len(batch_size_options):\n",
    "                            batch_size = batch_size_options[batch_size_choice]\n",
    "                            break\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                    print(\"Invalid choice, please try again.\")\n",
    "\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "\n",
    "print(f\"You selected: {selected_model_variant}\")\n",
    "print(f\"Testing option: {'yes' if test_option == '1' else 'no'}\")\n",
    "if test_option == \"1\":\n",
    "    print(f\"Testing on: {'image' if test_type == '0' else 'video'} at path: {path}\")\n",
    "print(f\"Quantize option: {'yes' if quantize_option == '1' else 'no'}\")\n",
    "if quantize_option == \"1\":\n",
    "    print(f\"Quantization precision: {'fp16' if quantize_bits == '0' else 'fp32'}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cd8e46-52c5-4539-9d34-38c1bf7e9465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/workspace/mmyolo/data/cat/annotations'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "parent_directory = os.path.dirname(annotation_path)\n",
    "parent_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7840c0bc-1517-4232-834e-de96358f2614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noise': True,\n",
       " 'denoise': False,\n",
       " 'contrast': True,\n",
       " 'brightness': True,\n",
       " 'rotation': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7baa4af7-f365-4268-b0a7-60ea640520d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation_path=\"/root/workspace/mmyolo/data/cat/annotations/annotations_all.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ba3dfe-ab76-4945-ac49-f9a64742e23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_with_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59dbf36c-ce77-4bdd-99e9-a532a3dd5707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/workspace/mmyolo/data/cat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdcacd65-12c7-4374-9bb1-d56bf120f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../..\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def extract_random_middle_part(annotation_file_path, dataset_root):\n",
    "    with open(annotation_file_path, 'r') as f:\n",
    "        annotation_data = json.load(f)\n",
    "\n",
    "    # Get a random image from the list\n",
    "    random_image = random.choice(annotation_data[\"images\"])\n",
    "\n",
    "    file_path = random_image[\"file_name\"]\n",
    "    relative_path = os.path.relpath(file_path, dataset_root)\n",
    "    middle_part = os.path.dirname(relative_path)\n",
    "\n",
    "    return middle_part\n",
    "\n",
    "# Example usage\n",
    "# annotation_file_path = \"/path/to/your/annotation_file.json\"\n",
    "# dataset_root = \"/home/viso/sample_dataset\"\n",
    "\n",
    "random_middle_part = extract_random_middle_part(annotation_path, dataset_root)\n",
    "\n",
    "# Print the extracted middle part\n",
    "print(random_middle_part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce4d219-53ef-44cb-8668-869bec392d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_middle_part='images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f090aef-8797-4882-a1a4-694a10c8fe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_middle_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "805e31ff-dec6-4a88-845b-ff8b1118f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/workspace/mmyolo'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125dd5c8-4717-4850-85da-5862e39a230c",
   "metadata": {},
   "source": [
    "# Generating metainfo for the config based on the annotation file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49a1b83e-f5ac-4274-a390-315bc8ba32be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names: ['cat']\n",
      "Number of Classes: 1\n",
      "Metainfo: {'classes': ['cat'], 'palette': [(0, 0, 0)]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(annotation_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "classes = [c['name'] for c in data['categories']]\n",
    "NUM_CLASSES = len(classes)\n",
    "palette = []\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    r = (i * 50) % 255\n",
    "    g = (i * 100) % 255\n",
    "    b = (i * 150) % 255\n",
    "    palette.append((r, g, b))\n",
    "\n",
    "metainfo = {\n",
    "    'classes': classes,\n",
    "    'palette': palette\n",
    "}\n",
    "class_names=metainfo['classes']\n",
    "print(\"Class Names:\", class_names)\n",
    "print(\"Number of Classes:\", NUM_CLASSES)\n",
    "print(\"Metainfo:\", metainfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a5a75d-6110-47eb-b53b-31fd3481e817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c1afd-9791-4639-b3f5-f250555d9144",
   "metadata": {},
   "source": [
    "# Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057d901-bc51-408c-b982-83f9121b146a",
   "metadata": {},
   "source": [
    "# converting the annotations from json to txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81e2db8f-c315-412d-b9f8-cf201eca6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "# Load COCO annotations \n",
    "def convert_coco_to_yolo_old(annotation_path,dataset_root):\n",
    "    print(\".......... in convert_coco_to_yolo ..........\")\n",
    "    print(annotation_path)\n",
    "    # Ensure the \"txt_files\" directory exists or create it\n",
    "    txt_files_dir = os.path.join(dataset_root, 'txt_files')\n",
    "    print(txt_files_dir)\n",
    "    if not os.path.exists(txt_files_dir):\n",
    "        os.makedirs(txt_files_dir)\n",
    "\n",
    "    with open(annotation_path) as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "\n",
    "    # Create lists to store image info and annotations\n",
    "    image_ids = []\n",
    "    image_info = []\n",
    "    annotations = []\n",
    "    print(\"image_ids\",image_ids)\n",
    "    print(\"image_info\",image_info)\n",
    "    print(\"annotations\",annotations)\n",
    "    # Get image ids and image info \n",
    "    for img in coco['images']:\n",
    "        image_ids.append(img['id'])\n",
    "        image_info.append({'file_name': img['file_name'],\n",
    "                           'width': img['width'],\n",
    "                           'height': img['height']})\n",
    "        # print(\"image id are\",image_ids)\n",
    "    # print(\".........................\")\n",
    "    # Get annotations \n",
    "    for ann in coco['annotations']:\n",
    "        bbox = ann['bbox']\n",
    "        x, y, width, height = bbox\n",
    "        image_id = ann['image_id']\n",
    "        category_id = ann['category_id']\n",
    "        # print(\"image id 'ssssssssss\",image_id)\n",
    "        # Convert to relative cooridnates \n",
    "        x_rel = x/image_info[image_id-1]['width'] \n",
    "        y_rel = y/image_info[image_id-1]['height']\n",
    "        width_rel = width/image_info[image_id-1]['width']\n",
    "        height_rel = height/image_info[image_id-1]['height']\n",
    "\n",
    "        annotation = (category_id, x_rel, y_rel, width_rel, height_rel)\n",
    "        annotations.append({'image_id': image_id, 'annotation': annotation})\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    yolo_annotations = []\n",
    "    for annotation in annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        # print(\"image_id\",image_id)\n",
    "        category_id, x, y, width, height = annotation['annotation']\n",
    "\n",
    "        # Calculate center x, y \n",
    "        x_center = x + width/2\n",
    "        y_center = y + height/2\n",
    "\n",
    "        yolo_annotation = f\"{category_id} {x_center} {y_center} {width} {height}\\n\"\n",
    "        yolo_annotations.append({'image_id': image_id, 'annotation': yolo_annotation})\n",
    "\n",
    "    # Group annotations by image    \n",
    "    yolo_files = {}\n",
    "    for annotation in yolo_annotations:\n",
    "        print(yolo_annotations)\n",
    "        image_id = annotation['image_id']\n",
    "        yolo_annotation = annotation['annotation']\n",
    "        if image_id not in yolo_files:\n",
    "            yolo_files[image_id] = [yolo_annotation]\n",
    "        else:\n",
    "            yolo_files[image_id].append(yolo_annotation)\n",
    "\n",
    "\n",
    "    # Save annotation files\n",
    "        for image_id, annotations in yolo_files.items(): \n",
    "            file_name = image_info[image_id-1]['file_name']\n",
    "            # print('.1.',file_name)\n",
    "            file_name = file_name.split('.')[0] + '.txt'\n",
    "            # print('.2.',file_name)\n",
    "            base_name = os.path.splitext(os.path.basename(file_name))[0]  # Get the base name without extension\n",
    "\n",
    "            # Construct the destination .txt file name\n",
    "            txt_file_name = base_name + '.txt'\n",
    "            file_path = os.path.join(txt_files_dir, txt_file_name)\n",
    "\n",
    "            #print(f\"Saving to: {file_path}\")\n",
    "\n",
    "            with open(file_path, 'w') as f:\n",
    "            # with open(txt_files_dir, 'w') as f:\n",
    "                for annotation in annotations:\n",
    "                    f.write(annotation)\n",
    "\n",
    "            # with open(file_path, 'w') as f:\n",
    "            #     for annotation in annotations:\n",
    "            #         f.write(annotation + '\\n')\n",
    "            #         # destination_path = os.path.join(txt_files_dir, file_name)\n",
    "            #         shutil.move(file_path, txt_files_dir)\n",
    "\n",
    "\n",
    "\n",
    "    # Save image list file\n",
    "    # with open('train.txt', 'w') as f:\n",
    "    #     for image_id in image_ids:\n",
    "    #         file_name = image_info[image_id-1]['file_name']\n",
    "    #         f.write(file_name + '\\n')\n",
    "    \n",
    "#convert_coco_to_yolo(annotation_path, dataset_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ced0d4e-d85e-4576-abaa-10428cc40e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def convert_coco_to_yolo(annotation_path, dataset_root):\n",
    "    print(\".......... in convert_coco_to_yolo ..........\")\n",
    "    print(annotation_path)\n",
    "\n",
    "    # Ensure the \"txt_files\" directory exists or create it\n",
    "    txt_files_dir = os.path.join(dataset_root, 'txt_files')\n",
    "    print(txt_files_dir)\n",
    "    if not os.path.exists(txt_files_dir):\n",
    "        os.makedirs(txt_files_dir)\n",
    "\n",
    "    with open(annotation_path) as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    # Create lists to store image info and annotations\n",
    "    image_info = {}\n",
    "    annotations = []\n",
    "\n",
    "    # Get image info\n",
    "    for img in coco['images']:\n",
    "        image_info[img['id']] = {'file_name': img['file_name'],\n",
    "                                  'width': img['width'],\n",
    "                                  'height': img['height']}\n",
    "\n",
    "    # Get annotations \n",
    "    for ann in coco['annotations']:\n",
    "        bbox = ann['bbox']\n",
    "        x, y, width, height = bbox\n",
    "        image_id = ann['image_id']\n",
    "        if image_id not in image_info:\n",
    "            print(f\"Warning: Image ID {image_id} not found in image info\")\n",
    "            continue\n",
    "\n",
    "        category_id = ann['category_id']\n",
    "        \n",
    "        # Convert to relative coordinates \n",
    "        x_rel = x / image_info[image_id]['width']\n",
    "        y_rel = y / image_info[image_id]['height']\n",
    "        width_rel = width / image_info[image_id]['width']\n",
    "        height_rel = height / image_info[image_id]['height']\n",
    "\n",
    "        annotation = (category_id, x_rel, y_rel, width_rel, height_rel)\n",
    "        annotations.append({'image_id': image_id, 'annotation': annotation})\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    yolo_annotations = []\n",
    "    for annotation in annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        category_id, x, y, width, height = annotation['annotation']\n",
    "\n",
    "        # Calculate center x, y \n",
    "        x_center = x + width / 2\n",
    "        y_center = y + height / 2\n",
    "\n",
    "        yolo_annotation = f\"{category_id} {x_center} {y_center} {width} {height}\\n\"\n",
    "        yolo_annotations.append({'image_id': image_id, 'annotation': yolo_annotation})\n",
    "\n",
    "    # Group annotations by image    \n",
    "    yolo_files = {}\n",
    "    for annotation in yolo_annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        yolo_annotation = annotation['annotation']\n",
    "        if image_id not in yolo_files:\n",
    "            yolo_files[image_id] = [yolo_annotation]\n",
    "        else:\n",
    "            yolo_files[image_id].append(yolo_annotation)\n",
    "\n",
    "    # Save annotation files\n",
    "    for image_id, annotations in yolo_files.items(): \n",
    "        if image_id not in image_info:\n",
    "            print(f\"Error: Image ID {image_id} not found in image info\")\n",
    "            continue\n",
    "            \n",
    "        file_name = image_info[image_id]['file_name']\n",
    "        base_name = os.path.splitext(os.path.basename(file_name))[0]  # Get the base name without extension\n",
    "        txt_file_name = base_name + '.txt'\n",
    "        file_path = os.path.join(txt_files_dir, txt_file_name)\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            for annotation in annotations:\n",
    "                f.write(annotation)\n",
    "\n",
    "    # Save image list file\n",
    "    # with open('train.txt', 'w') as f:\n",
    "    #     for image_id in image_ids:\n",
    "    #         file_name = image_info[image_id-1]['file_name']\n",
    "    #         f.write(file_name + '\\n')\n",
    "\n",
    "# Now let's call the function\n",
    "# annotation_path = \"/home/viso/sample_data/annotations/total_annotations.json\"\n",
    "# dataset_root = \"/home/viso/sample_data/augmented_images\"\n",
    "# convert_coco_to_yolo(annotation_path, dataset_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0b864-c976-4340-aa47-58a5e33d3a72",
   "metadata": {},
   "source": [
    "# creating the config file for the data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16606162-77b5-4703-8848-403194b84f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_and_save_config(random_middle_part, dataset_root,AUGMENTATIONS):\n",
    "    print(\"............edit_and_save_config..............\")\n",
    "    # %cd /home/viso/datasets/enhance_script\n",
    "    import json\n",
    "    new_config_path = '/root/workspace/mmyolo/quantize/dataset_enhance_config.json'\n",
    "    original_config_path = '/root/workspace/mmyolo/quantize/dataset_enhance_config-dummy.json'\n",
    "    # Load the original config\n",
    "    with open(original_config_path) as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Modify the content as needed\n",
    "    config[\"original_image_folder\"] = f'{dataset_root}/{random_middle_part}'\n",
    "    config[\"original_label_folder\"] = f'{dataset_root}/txt_files'\n",
    "    config[\"enhance_image_folder\"] = f'{dataset_root}/train'\n",
    "    config[\"enhance_label_folder\"] = f'{dataset_root}/train'\n",
    "    config[\"augmentations\"] = {\n",
    "        \"noise\": AUGMENTATIONS['noise'],\n",
    "        \"denoise\": AUGMENTATIONS['denoise'],\n",
    "        \"contrast\": AUGMENTATIONS['contrast'],\n",
    "        \"brightness\": AUGMENTATIONS['brightness'],\n",
    "        \"rotation\": AUGMENTATIONS['rotation']\n",
    "    }\n",
    "    # Save the modified config to a new file\n",
    "    with open(new_config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# random_middle_part = 'images'\n",
    "# dataset_root = '/home/viso/sample_dataset'  # Provide the actual path\n",
    "# edit_and_save_config(original_config_path, new_config_path, random_middle_part, dataset_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba6bb0-02f1-45f7-9263-cdeb04c10893",
   "metadata": {},
   "source": [
    "# Getting all the image_paths in the txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbb9a9a2-48c3-4777-a1b1-672c853c256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_image_paths(folder_path, extensions=[\".jpg\", \".png\"]):\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    return image_paths\n",
    "\n",
    "def write_paths_to_file(image_paths, output_file=f\"{dataset_root}/train.txt\"):\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for path in image_paths:\n",
    "            file.write(path + \"\\n\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# folder_path = \"/home/viso/sample_data/augmented_imagges\"  # Replace with the actual path to your folder\n",
    "    # image_paths = get_image_paths(folder_path)\n",
    "    # write_paths_to_file(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcf5beb9-8b91-4941-9bbd-fa2751095a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def update_config_with_class_names(class_names):\n",
    "    dummy_main = '/root/workspace/mmyolo/quantize/dummy_main.py'\n",
    "    main='/root/workspace/mmyolo/quantize/main.py'\n",
    "    with open(dummy_main, 'r') as f:\n",
    "        cfg_content = f.read()\n",
    "\n",
    "    # Replace specific lines with new values\n",
    "    cfg_content = cfg_content.replace(\"classes =\", f\"classes = {class_names}\")\n",
    "\n",
    "    # Write the updated content back to the configuration file\n",
    "    with open(main, 'w') as custom_cfg_file:\n",
    "        custom_cfg_file.write(cfg_content)\n",
    "\n",
    "# Example usage:\n",
    "# number_of_classes = 10  # Replace with the actual number of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdd78478-fdca-41c9-990e-a1d3c8c5ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......... in convert_coco_to_yolo ..........\n",
      "/root/workspace/mmyolo/data/cat/annotations/annotations_all.json\n",
      "/root/workspace/mmyolo/data/cat/txt_files\n",
      "............edit_and_save_config..............\n",
      "/root/workspace/mmyolo/quantize\n",
      "<class 'dict'>\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "10/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "20/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "30/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "40/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "50/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "60/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "70/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "80/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "90/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "100/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "110/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "120/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "130/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "140/142\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Augmentations dictionary: {'noise': True, 'denoise': False, 'contrast': True, 'brightness': True, 'rotation': True}\n",
      "Type of augmentations: <class 'dict'>\n",
      "Value of augmentations['noise']: True\n",
      "en_noise True\n",
      "en_contrast True\n",
      "en_bright True\n",
      "Requirement already satisfied: imagesize in /opt/conda/lib/python3.8/site-packages (1.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mStart!\n",
      "Processing 853 ...Finished!\n",
      "/root/workspace/mmyolo/data/cat\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "if train_with_augmentation=='1':\n",
    "    # %cd /home/viso/notebooks\n",
    "    # %run ./aug.ipynb\n",
    "    convert_coco_to_yolo(annotation_path, dataset_root)\n",
    "    edit_and_save_config(random_middle_part, dataset_root,AUGMENTATIONS)\n",
    "    %cd /root/workspace/mmyolo/quantize\n",
    "    !python run_dataset_enhance.py\n",
    "    # %cd /home/viso/github/Yolo-to-COCO-format-converter\n",
    "    update_config_with_class_names(class_names)\n",
    "    !pip install imagesize\n",
    "    !python main.py --path {dataset_root} --output output_json.json\n",
    "    %pwd\n",
    "    shutil.copy('/root/workspace/mmyolo/quantize/output/output_json.json',parent_directory)\n",
    "    %cd {dataset_root}\n",
    "    folder_path=f'{dataset_root}/train'\n",
    "    image_paths = get_image_paths(folder_path)\n",
    "    write_paths_to_file(image_paths)\n",
    "    with open('object.names', 'w') as f:\n",
    "        for class_name in class_names:\n",
    "            f.write(class_name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "941c9457-ac5f-47e6-b665-b3e671aabab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmyolo/data/cat/annotations/output_json.json\n"
     ]
    }
   ],
   "source": [
    "if train_with_augmentation=='1':\n",
    "    annotation_path = f'{parent_directory}/output_json.json'\n",
    "    print(annotation_path)\n",
    "    random_middle_part = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7381d75-7922-4a96-9638-8d63c026b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(AUGMENTATIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0210a761-5947-4ba5-bbf4-4f2236e69e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUGMENTATIONS['noise']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6649f31-69dd-4902-b18d-af266a872d43",
   "metadata": {},
   "source": [
    "# split the annotation file into train , test and validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5add7c-530d-4662-9ea9-923c50fda5c6",
   "metadata": {},
   "source": [
    "### If there is single annotation file , that can divide into train , test and validation (coco format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "179e8f58-6f33-4fb1-b990-911115a341d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/workspace/mmyolo/data/cat'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "730ea6ad-a89d-45b5-a11a-b570eb70fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hRequirement already satisfied: funcy in /opt/conda/lib/python3.8/site-packages (2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install funcy\n",
    "!pip install argparse\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abf50abe-116d-476b-bb6b-e8a98532582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'cocosplit_train_test_valid.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python cocosplit_train_test_valid.py \\\n",
    "    --annotations \"{annotation_path}\" \\\n",
    "    --train_ratio {train_percentage} \\\n",
    "    --valid_ratio {val_percentage} \\\n",
    "    --test_ratio {test_percentage} \\\n",
    "    --trainJson_name train.json \\\n",
    "    --validJson_name val.json \\\n",
    "    --testJson_name test.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8bed4fc-05c2-4fce-831e-774a57c5e29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/workspace/mmyolo/data/cat'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "379527e5-90ea-43fa-90d3-9a7ee8705c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations/train.json annotations/val.json annotations/test.json\n",
      "/root/workspace/mmyolo/data/cat/annotations\n"
     ]
    }
   ],
   "source": [
    "import os , shutil\n",
    "# dataset_root = '/home/viso/datasets/viso_datasets/construction-demo'\n",
    "\n",
    "# parent_directory = os.path.dirname(annotation_path)\n",
    "shutil.copy('/root/workspace/mmyolo/test.json',parent_directory)\n",
    "shutil.copy('/root/workspace/mmyolo/val.json',parent_directory)\n",
    "shutil.copy('/root/workspace/mmyolo/train.json',parent_directory)\n",
    "\n",
    "train_json = os.path.join(parent_directory, 'train.json')\n",
    "val_json = os.path.join(parent_directory, 'val.json')\n",
    "test_json = os.path.join(parent_directory, 'test.json')\n",
    "\n",
    "# Remove the dataset_root prefix using os.path.relpath\n",
    "train_json_relpath = os.path.relpath(train_json, dataset_root)\n",
    "val_json_relpath = os.path.relpath(val_json, dataset_root)\n",
    "test_json_relpath = os.path.relpath(test_json, dataset_root)\n",
    "\n",
    "print(train_json_relpath, val_json_relpath, test_json_relpath)\n",
    "print(parent_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d964eb5-bb9f-4b6c-8307-3194f9d7ac3f",
   "metadata": {},
   "source": [
    "# Yolox configuration setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0bc5ce8-a5fa-40f3-9bb5-cb7a6e30ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the selected model type is 'YOLOx'\n",
    "if selected_model_type == 'YOLOx':\n",
    "    # Provide the path to the user for modification\n",
    "    dummy_config = '/root/workspace/mmyolo/configs/yolox/custom_config.py'\n",
    "    custom_config_file_path_base = '/root/workspace/mmyolo/configs/yolox/yolox_s_fast_8xb8-300e_coco.py'  # Set your desired path\n",
    "\n",
    "    # Load the YOLOx config file\n",
    "    with open(dummy_config, 'r') as f:\n",
    "        cfg_content = f.read()\n",
    "\n",
    "    # Replace specific lines with new values\n",
    "    cfg_content = cfg_content.replace(\"data_root =\", f\"data_root = '{dataset_root}/'\")\n",
    "    cfg_content = cfg_content.replace(\"train_data_prefix =\", f\"train_data_prefix = '{random_middle_part}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_data_prefix =\", f\"val_data_prefix = '{random_middle_part}'\")\n",
    "    cfg_content = cfg_content.replace(\"train_ann_file =\", f\"train_ann_file = '{train_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_ann_file =\", f\"val_ann_file = '{val_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"num_classes =\", f\"num_classes = {NUM_CLASSES}\")\n",
    "    cfg_content = cfg_content.replace(\"meta_info =\", f\"meta_info = {metainfo}\")\n",
    "    cfg_content = cfg_content.replace(\"max_epochs =\", f\"max_epochs = {MAX_EPOCHS}\")\n",
    "    cfg_content = cfg_content.replace(\"train_batch_size_per_gpu =\", f\"train_batch_size_per_gpu = {BATCH_SIZE}\")\n",
    "\n",
    "    # Save the modified content to the new file\n",
    "    with open(custom_config_file_path_base, 'w') as custom_cfg_file:\n",
    "        custom_cfg_file.write(cfg_content)\n",
    "\n",
    "    print(f\"Custom config file has been created at {custom_config_file_path_base}.\")\n",
    "    print(\"dummy_config:\", dummy_config)\n",
    "    print(\"custom_config_file_path_base:\", custom_config_file_path_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bed28c-b4cb-4a35-b46d-81c339d32b88",
   "metadata": {},
   "source": [
    "# Yolov7 configuration setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "007e4441-bbff-466d-90ce-03bc6847797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model_type == 'YOLOv7':\n",
    "    dummy_config = '/root/workspace/mmyolo/configs/yolov7/custom_config.py'\n",
    "    custom_config_file_path_base = '/root/workspace/mmyolo/configs/yolov7/yolov7_l_syncbn_fast_8x16b-300e_coco.py'  # Set your desired path\n",
    "\n",
    "    # Load the YOLOx config file\n",
    "    with open(dummy_config, 'r') as f:\n",
    "        cfg_content = f.read()\n",
    "\n",
    "    # Replace specific lines with new values\n",
    "    cfg_content = cfg_content.replace(\"data_root =\", f\"data_root = '{dataset_root}/'\")\n",
    "    cfg_content = cfg_content.replace(\"train_data_prefix =\", f\"train_data_prefix = '{random_middle_part}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_data_prefix =\", f\"val_data_prefix = '{random_middle_part}'\")\n",
    "    cfg_content = cfg_content.replace(\"train_ann_file =\", f\"train_ann_file = '{train_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_ann_file =\", f\"val_ann_file = '{val_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"num_classes =\", f\"num_classes = {NUM_CLASSES}\")\n",
    "    cfg_content = cfg_content.replace(\"meta_info =\", f\"meta_info = {metainfo}\")\n",
    "    cfg_content = cfg_content.replace(\"max_epochs =\", f\"max_epochs = {MAX_EPOCHS}\")\n",
    "    cfg_content = cfg_content.replace(\"train_batch_size_per_gpu =\", f\"train_batch_size_per_gpu = {BATCH_SIZE}\")\n",
    "\n",
    "    # Save the modified content to the new file\n",
    "    with open(custom_config_file_path_base, 'w') as custom_cfg_file:\n",
    "        custom_cfg_file.write(cfg_content)\n",
    "\n",
    "    print(f\"Custom config file has been created at {custom_config_file_path_base}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01c3fc-88b1-4ec2-880e-ea31adf4284f",
   "metadata": {},
   "source": [
    "# Rtmdet configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "981330f5-0a26-4c0e-813e-ee4cef295fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model_type == 'RTMDET':\n",
    "    dummy_config = '/root/workspace/mmyolo/configs/rtmdet/custom_config.py'\n",
    "    custom_config_file_path_base = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_l_syncbn_fast_8xb32-300e_coco.py'  # Set your desired path\n",
    "\n",
    "    # Load the YOLOx config file\n",
    "    with open(dummy_config, 'r') as f:\n",
    "        cfg_content = f.read()\n",
    "\n",
    "    # Replace specific lines with new values\n",
    "    cfg_content = cfg_content.replace(\"data_root =\", f\"data_root = '{dataset_root}/'\")\n",
    "    cfg_content = cfg_content.replace(\"train_data_prefix =\", f\"train_data_prefix = '{random_middle_part}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_data_prefix =\", f\"val_data_prefix = '{random_middle_part}'\")\n",
    "    cfg_content = cfg_content.replace(\"train_ann_file =\", f\"train_ann_file = '{train_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_ann_file =\", f\"val_ann_file = '{val_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"num_classes =\", f\"num_classes = {NUM_CLASSES}\")\n",
    "    cfg_content = cfg_content.replace(\"meta_info =\", f\"meta_info = {metainfo}\")\n",
    "    cfg_content = cfg_content.replace(\"max_rrandom_middle_partandom_middle_partepochs =\", f\"max_epochs = {MAX_EPOCHS}\")\n",
    "    cfg_content = cfg_content.replace(\"train_batch_size_per_gpu =\", f\"train_batch_size_per_gpu = {BATCH_SIZE}\")\n",
    "\n",
    "    # Save the modified content to the new file\n",
    "    with open(custom_config_file_path_base, 'w') as custom_cfg_file:\n",
    "        custom_cfg_file.write(cfg_content)\n",
    "\n",
    "    print(f\"Custom config file has been created at {custom_config_file_path_base}.\")\n",
    "    print(\"dummy_config:\", dummy_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cc427b9-d53a-46ca-b389-b560cdb76d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model_variant=='yolox_tiny':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_tiny_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolox_s':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_s_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolox_m':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_m_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolox_l':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_l_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolox_x':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_x_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_tiny':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_tiny_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_l':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_l_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_x':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_x_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_w':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_w-p6_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_e':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_e_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_tiny':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_tiny_syncbn_fast_8xb32-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_s':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_s_syncbn_fast_8xb32-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_l':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_l_syncbn_fast_8xb32-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_m':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_m_syncbn_fast_8xb32-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_x':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_x_syncbn_fast_8xb32-300e_coco.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169e7c1b-0e54-408e-a820-b0ce815eee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config_file_path=config_file_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983be65b-97e5-4a1b-b71f-5645356b78f0",
   "metadata": {},
   "source": [
    "# train the data with the selected model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f15b54d-a7fa-4e47-8077-baae4ecd0cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmyolo\n"
     ]
    }
   ],
   "source": [
    "%cd /root/workspace/mmyolo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bce68745-7330-4f09-80c3-b21b808b3d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rtmdet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rtmdet_m_syncbn_fast_8xb32-300e_coco.py'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model_type=selected_model_type.lower()\n",
    "print(selected_model_type)\n",
    "custom_config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "846081d3-3908-44cc-8e80-f4d8575ea736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c75006f9-7aa4-4e13-b0d2-0eea214c6636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/01 16:52:07 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
      "05/01 16:52:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1262772697\n",
      "    GPU 0: Tesla T4\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.10.0\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "    TorchVision: 0.11.0\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1262772697\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/01 16:52:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "_backend_args = None\n",
      "_multiscale_resize_transforms = [\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                320,\n",
      "                320,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    320,\n",
      "                    320,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                960,\n",
      "                960,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    960,\n",
      "                    960,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "]\n",
      "backend_args = None\n",
      "base_lr = 0.004\n",
      "batch_shapes_cfg = dict(\n",
      "    batch_size=32,\n",
      "    extra_pad_ratio=0.5,\n",
      "    img_size=640,\n",
      "    size_divisor=32,\n",
      "    type='BatchShapePolicy')\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        ema_type='ExpMomentumEMA',\n",
      "        momentum=0.0002,\n",
      "        priority=49,\n",
      "        strict_load=False,\n",
      "        type='EMAHook',\n",
      "        update_buffers=True),\n",
      "    dict(\n",
      "        switch_epoch=-10,\n",
      "        switch_pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.1,\n",
      "                    2.0,\n",
      "                ),\n",
      "                resize_type='mmdet.Resize',\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='mmdet.RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='mmdet.RandomCrop'),\n",
      "            dict(type='mmdet.YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='mmdet.Pad'),\n",
      "            dict(type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        type='mmdet.PipelineSwitchHook'),\n",
      "]\n",
      "data_root = '/root/workspace/mmyolo/data/cat/'\n",
      "dataset_type = 'YOLOv5CocoDataset'\n",
      "deepen_factor = 0.67\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=10, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
      "default_scope = 'mmyolo'\n",
      "dsl_topk = 13\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_scale = (\n",
      "    640,\n",
      "    640,\n",
      ")\n",
      "img_scales = [\n",
      "    (\n",
      "        640,\n",
      "        640,\n",
      "    ),\n",
      "    (\n",
      "        320,\n",
      "        320,\n",
      "    ),\n",
      "    (\n",
      "        960,\n",
      "        960,\n",
      "    ),\n",
      "]\n",
      "launcher = 'none'\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "loss_bbox_weight = 2.0\n",
      "loss_cls_weight = 1.0\n",
      "lr_start_factor = 1e-05\n",
      "max_epochs = 10\n",
      "max_keep_ckpts = 3\n",
      "meta_info = dict(\n",
      "    classes=[\n",
      "        'cat',\n",
      "    ], palette=[\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            0,\n",
      "        ),\n",
      "    ])\n",
      "mixup_max_cached_images = 20\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        arch='P5',\n",
      "        channel_attention=True,\n",
      "        deepen_factor=0.67,\n",
      "        expand_ratio=0.5,\n",
      "        norm_cfg=dict(type='BN'),\n",
      "        type='CSPNeXt',\n",
      "        widen_factor=0.75),\n",
      "    bbox_head=dict(\n",
      "        bbox_coder=dict(type='DistancePointBBoxCoder'),\n",
      "        head_module=dict(\n",
      "            act_cfg=dict(inplace=True, type='SiLU'),\n",
      "            feat_channels=256,\n",
      "            featmap_strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            in_channels=256,\n",
      "            norm_cfg=dict(type='BN'),\n",
      "            num_classes=1,\n",
      "            pred_kernel_size=1,\n",
      "            share_conv=True,\n",
      "            stacked_convs=2,\n",
      "            type='RTMDetSepBNHeadModule',\n",
      "            widen_factor=0.75),\n",
      "        loss_bbox=dict(loss_weight=2.0, type='mmdet.GIoULoss'),\n",
      "        loss_cls=dict(\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='mmdet.QualityFocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        prior_generator=dict(\n",
      "            offset=0, strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ], type='mmdet.MlvlPointGenerator'),\n",
      "        type='RTMDetHead'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=False,\n",
      "        mean=[\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.12,\n",
      "            58.395,\n",
      "        ],\n",
      "        type='YOLOv5DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        deepen_factor=0.67,\n",
      "        expand_ratio=0.5,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        norm_cfg=dict(type='BN'),\n",
      "        num_csp_blocks=3,\n",
      "        out_channels=256,\n",
      "        type='CSPNeXtPAFPN',\n",
      "        widen_factor=0.75),\n",
      "    test_cfg=dict(\n",
      "        max_per_img=300,\n",
      "        multi_label=True,\n",
      "        nms=dict(iou_threshold=0.65, type='nms'),\n",
      "        nms_pre=30000,\n",
      "        score_thr=0.001),\n",
      "    train_cfg=dict(\n",
      "        allowed_border=-1,\n",
      "        assigner=dict(\n",
      "            iou_calculator=dict(type='mmdet.BboxOverlaps2D'),\n",
      "            num_classes=1,\n",
      "            topk=13,\n",
      "            type='BatchDynamicSoftLabelAssigner'),\n",
      "        debug=False,\n",
      "        pos_weight=-1),\n",
      "    type='YOLODetector')\n",
      "model_test_cfg = dict(\n",
      "    max_per_img=300,\n",
      "    multi_label=True,\n",
      "    nms=dict(iou_threshold=0.65, type='nms'),\n",
      "    nms_pre=30000,\n",
      "    score_thr=0.001)\n",
      "mosaic_max_cached_images = 40\n",
      "norm_cfg = dict(type='BN')\n",
      "num_classes = 1\n",
      "num_epochs_stage2 = 20\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.004, type='AdamW', weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1000, start_factor=1e-05,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=5,\n",
      "        begin=5,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=10,\n",
      "        eta_min=0.0002,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "persistent_workers = True\n",
      "qfl_beta = 2.0\n",
      "random_resize_ratio_range = (\n",
      "    0.1,\n",
      "    2.0,\n",
      ")\n",
      "resume = False\n",
      "save_checkpoint_intervals = 10\n",
      "strides = [\n",
      "    8,\n",
      "    16,\n",
      "    32,\n",
      "]\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/test.json',\n",
      "        batch_shapes_cfg=dict(\n",
      "            batch_size=32,\n",
      "            extra_pad_ratio=0.5,\n",
      "            img_size=640,\n",
      "            size_divisor=32,\n",
      "            type='BatchShapePolicy'),\n",
      "        data_prefix=dict(img='images'),\n",
      "        data_root='/root/workspace/mmyolo/data/cat/',\n",
      "        metainfo=dict(classes=[\n",
      "            'cat',\n",
      "        ], palette=[\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'pad_param',\n",
      "                ),\n",
      "                type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='/root/workspace/mmyolo/data/cat/annotations/test.json',\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='mmdet.CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(scale=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='YOLOv5KeepRatioResize'),\n",
      "    dict(\n",
      "        allow_scale_up=False,\n",
      "        pad_val=dict(img=114),\n",
      "        scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='LetterResize'),\n",
      "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "            'pad_param',\n",
      "        ),\n",
      "        type='mmdet.PackDetInputs'),\n",
      "]\n",
      "train_ann_file = 'annotations/test.json'\n",
      "train_batch_size_per_gpu = 4\n",
      "train_cfg = dict(\n",
      "    dynamic_intervals=[\n",
      "        (\n",
      "            -10,\n",
      "            1,\n",
      "        ),\n",
      "    ],\n",
      "    max_epochs=10,\n",
      "    type='EpochBasedTrainLoop',\n",
      "    val_interval=10)\n",
      "train_data_prefix = 'images'\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    collate_fn=dict(type='yolov5_collate'),\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/test.json',\n",
      "        data_prefix=dict(img='images'),\n",
      "        data_root='/root/workspace/mmyolo/data/cat/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(classes=[\n",
      "            'cat',\n",
      "        ], palette=[\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                img_scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                max_cached_images=40,\n",
      "                pad_val=114.0,\n",
      "                type='Mosaic',\n",
      "                use_cached=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.1,\n",
      "                    2.0,\n",
      "                ),\n",
      "                resize_type='mmdet.Resize',\n",
      "                scale=(\n",
      "                    1280,\n",
      "                    1280,\n",
      "                ),\n",
      "                type='mmdet.RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='mmdet.RandomCrop'),\n",
      "            dict(type='mmdet.YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='mmdet.Pad'),\n",
      "            dict(max_cached_images=20, type='YOLOv5MixUp', use_cached=True),\n",
      "            dict(type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_num_workers = 10\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        img_scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        max_cached_images=40,\n",
      "        pad_val=114.0,\n",
      "        type='Mosaic',\n",
      "        use_cached=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        resize_type='mmdet.Resize',\n",
      "        scale=(\n",
      "            1280,\n",
      "            1280,\n",
      "        ),\n",
      "        type='mmdet.RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='mmdet.RandomCrop'),\n",
      "    dict(type='mmdet.YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "    dict(\n",
      "        pad_val=dict(img=(\n",
      "            114,\n",
      "            114,\n",
      "            114,\n",
      "        )),\n",
      "        size=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='mmdet.Pad'),\n",
      "    dict(max_cached_images=20, type='YOLOv5MixUp', use_cached=True),\n",
      "    dict(type='mmdet.PackDetInputs'),\n",
      "]\n",
      "train_pipeline_stage2 = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        resize_type='mmdet.Resize',\n",
      "        scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='mmdet.RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='mmdet.RandomCrop'),\n",
      "    dict(type='mmdet.YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "    dict(\n",
      "        pad_val=dict(img=(\n",
      "            114,\n",
      "            114,\n",
      "            114,\n",
      "        )),\n",
      "        size=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='mmdet.Pad'),\n",
      "    dict(type='mmdet.PackDetInputs'),\n",
      "]\n",
      "tta_model = dict(\n",
      "    tta_cfg=dict(max_per_img=300, nms=dict(iou_threshold=0.65, type='nms')),\n",
      "    type='mmdet.DetTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            640,\n",
      "                            640,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                640,\n",
      "                                640,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            320,\n",
      "                            320,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                320,\n",
      "                                320,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            960,\n",
      "                            960,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                960,\n",
      "                                960,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "            ],\n",
      "            [\n",
      "                dict(prob=1.0, type='mmdet.RandomFlip'),\n",
      "                dict(prob=0.0, type='mmdet.RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_id',\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'scale_factor',\n",
      "                        'pad_param',\n",
      "                        'flip',\n",
      "                        'flip_direction',\n",
      "                    ),\n",
      "                    type='mmdet.PackDetInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_ann_file = 'annotations/test.json'\n",
      "val_batch_size_per_gpu = 32\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_data_prefix = 'images'\n",
      "val_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/test.json',\n",
      "        batch_shapes_cfg=dict(\n",
      "            batch_size=32,\n",
      "            extra_pad_ratio=0.5,\n",
      "            img_size=640,\n",
      "            size_divisor=32,\n",
      "            type='BatchShapePolicy'),\n",
      "        data_prefix=dict(img='images'),\n",
      "        data_root='/root/workspace/mmyolo/data/cat/',\n",
      "        metainfo=dict(classes=[\n",
      "            'cat',\n",
      "        ], palette=[\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'pad_param',\n",
      "                ),\n",
      "                type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='/root/workspace/mmyolo/data/cat/annotations/test.json',\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='mmdet.CocoMetric')\n",
      "val_interval_stage2 = 1\n",
      "val_num_workers = 10\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='mmdet.DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "weight_decay = 0.05\n",
      "widen_factor = 0.75\n",
      "work_dir = './work_dirs/rtmdet_m_syncbn_fast_8xb32-300e_coco'\n",
      "\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_load_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(NORMAL      ) PipelineSwitchHook                 \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_save_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.2.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.3.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.2.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.2.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.2.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.3.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.3.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.3.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.2.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.2.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.main_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.main_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.short_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.short_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.final_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.final_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.0.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.main_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.main_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.short_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.short_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.final_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.final_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_layers.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsample_layers.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsample_layers.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsample_layers.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsample_layers.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.main_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.main_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.short_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.short_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.final_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.final_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.0.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.main_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.main_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.short_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.short_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.final_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.final_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.1.conv1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.1.conv1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.1.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.1.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.1.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_layers.1.blocks.1.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_layers.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_layers.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_layers.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_layers.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_layers.2.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_layers.2.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.0.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.0.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.0.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.0.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.head_module.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.1.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.1.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.head_module.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.1.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.1.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.head_module.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.2.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.2.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.head_module.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.2.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.cls_convs.2.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.0.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.0.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.0.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.0.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.head_module.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.1.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.1.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.head_module.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.1.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.1.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.head_module.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.2.0.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.2.0.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.head_module.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.2.1.bn.weight:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.reg_convs.2.1.bn.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.rtm_cls.0.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.rtm_cls.1.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.rtm_cls.2.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.rtm_reg.0.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.rtm_reg.1.bias:weight_decay=0.0\n",
      "05/01 16:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.head_module.rtm_reg.2.bias:weight_decay=0.0\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "05/01 16:52:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "05/01 16:52:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "05/01 16:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /root/workspace/mmyolo/work_dirs/rtmdet_m_syncbn_fast_8xb32-300e_coco.\n",
      "05/01 16:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Switch pipeline now!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/01 16:52:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:52:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4/4]  base_lr: 1.2052e-05 lr: 1.2052e-05  eta: 0:01:53  time: 3.1572  data_time: 0.3383  memory: 12154  loss: 0.0600  loss_cls: 0.0320  loss_bbox: 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/01 16:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 3.6698  time: 7.1453\n",
      "05/01 16:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4/4]  base_lr: 2.8068e-05 lr: 2.8068e-05  eta: 0:00:58  time: 1.8170  data_time: 0.2495  memory: 6860  loss: 0.0589  loss_cls: 0.0318  loss_bbox: 0.0271\n",
      "05/01 16:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 3.3126  time: 5.2981\n",
      "05/01 16:52:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:52:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4/4]  base_lr: 4.4084e-05 lr: 4.4084e-05  eta: 0:00:38  time: 1.3707  data_time: 0.2215  memory: 3709  loss: 0.0853  loss_cls: 0.0317  loss_bbox: 0.0535\n",
      "05/01 16:52:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:52:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:52:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 2.9552  time: 3.4208\n",
      "05/01 16:52:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:52:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4/4]  base_lr: 6.0099e-05 lr: 6.0099e-05  eta: 0:00:27  time: 1.1490  data_time: 0.2083  memory: 3709  loss: 0.1196  loss_cls: 0.0321  loss_bbox: 0.0875\n",
      "05/01 16:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 2.9497  time: 3.3977\n",
      "05/01 16:52:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:52:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4/4]  base_lr: 7.6115e-05 lr: 7.6115e-05  eta: 0:00:20  time: 1.0170  data_time: 0.2017  memory: 3709  loss: 0.1739  loss_cls: 0.0341  loss_bbox: 0.1398\n",
      "05/01 16:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 2.9539  time: 3.4226\n",
      "05/01 16:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4/4]  base_lr: 9.8283e-05 lr: 9.8283e-05  eta: 0:00:14  time: 0.9289  data_time: 0.1971  memory: 3709  loss: 0.2431  loss_cls: 0.0702  loss_bbox: 0.1729\n",
      "05/01 16:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 2.9582  time: 3.4369\n",
      "05/01 16:53:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:53:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4/4]  base_lr: 1.3706e-04 lr: 1.3706e-04  eta: 0:00:10  time: 0.8622  data_time: 0.1898  memory: 3709  loss: 0.2421  loss_cls: 0.0669  loss_bbox: 0.1752\n",
      "05/01 16:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 2.9656  time: 3.4451\n",
      "05/01 16:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4/4]  base_lr: 1.7857e-04 lr: 1.7857e-04  eta: 0:00:06  time: 0.8120  data_time: 0.1845  memory: 3709  loss: 0.3159  loss_cls: 0.0848  loss_bbox: 0.2310\n",
      "05/01 16:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 2.9798  time: 3.4697\n",
      "05/01 16:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4/4]  base_lr: 2.0438e-04 lr: 2.0438e-04  eta: 0:00:03  time: 0.7746  data_time: 0.1820  memory: 3709  loss: 0.3548  loss_cls: 0.0908  loss_bbox: 0.2641\n",
      "05/01 16:53:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:53:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:53:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 2.9639  time: 3.4601\n",
      "05/01 16:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet_m_syncbn_fast_8xb32-300e_coco_20240501_165207\n",
      "05/01 16:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4/4]  base_lr: 2.0279e-04 lr: 2.0279e-04  eta: 0:00:00  time: 0.7464  data_time: 0.1817  memory: 3709  loss: 0.4102  loss_cls: 0.1166  loss_bbox: 0.2936\n",
      "05/01 16:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
      "05/01 16:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 2.9598  time: 3.4231\n",
      "Command executed successfully\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Assuming config_file_path is something like \"yolox/config_file.py\"\n",
    "# config_file_path = config_file_path.split('/')[-1]\n",
    "command_line = f\"python tools/train.py configs/{selected_model_type}/{custom_config_file_path}\"\n",
    "\n",
    "# Run the command\n",
    "result = subprocess.run(command_line, shell=True)\n",
    "\n",
    "# Check the result\n",
    "if result.returncode == 0:\n",
    "    print(\"Command executed successfully\")\n",
    "else:\n",
    "    print(f\"Error executing the command. Return code: {result.returncode}\")\n",
    "    print(f\"Output: {result.stdout}\")\n",
    "    print(f\"Error: {result.stderr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a467bd3-538c-4157-a9e5-b606a0ee6eae",
   "metadata": {},
   "source": [
    "# testing with the trained model with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4ebf468-1b33-4f27-81ba-cec6279cd94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rtmdet_m_syncbn_fast_8xb32-300e_coco\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Remove the last .py extension\n",
    "custom_config_file_path_without_extension = os.path.splitext(custom_config_file_path)[0]\n",
    "\n",
    "print(custom_config_file_path_without_extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f44bbc9e-56f9-45fd-ba07-2bd8b180f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images='images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bcd7fd02-30cc-4662-b0da-266e1742a1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': ['cat'], 'palette': [(0, 0, 0)]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f427d975-1993-4add-8ae7-c36941559021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmyolo\n",
      "dummy_config: /root/workspace/mmyolo/configs/rtmdet/custom_config.py\n",
      "custom_config_file_path_base: /root/workspace/mmyolo/configs/rtmdet/rtmdet_l_syncbn_fast_8xb32-300e_coco.py\n",
      "/root/workspace/mmyolo\n",
      "05/01 16:53:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"log_processor\" registry tree. As a workaround, the current \"log_processor\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
      "05/01 16:53:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1162776163\n",
      "    GPU 0: Tesla T4\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "    PyTorch: 1.10.0\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "    TorchVision: 0.11.0\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1162776163\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/01 16:53:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "_backend_args = None\n",
      "_multiscale_resize_transforms = [\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                320,\n",
      "                320,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    320,\n",
      "                    320,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            dict(scale=(\n",
      "                960,\n",
      "                960,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    960,\n",
      "                    960,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "        ],\n",
      "        type='Compose'),\n",
      "]\n",
      "backend_args = None\n",
      "base_lr = 0.004\n",
      "batch_shapes_cfg = dict(\n",
      "    batch_size=32,\n",
      "    extra_pad_ratio=0.5,\n",
      "    img_size=640,\n",
      "    size_divisor=32,\n",
      "    type='BatchShapePolicy')\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        ema_type='ExpMomentumEMA',\n",
      "        momentum=0.0002,\n",
      "        priority=49,\n",
      "        strict_load=False,\n",
      "        type='EMAHook',\n",
      "        update_buffers=True),\n",
      "    dict(\n",
      "        switch_epoch=-10,\n",
      "        switch_pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.1,\n",
      "                    2.0,\n",
      "                ),\n",
      "                resize_type='mmdet.Resize',\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='mmdet.RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='mmdet.RandomCrop'),\n",
      "            dict(type='mmdet.YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='mmdet.Pad'),\n",
      "            dict(type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        type='mmdet.PipelineSwitchHook'),\n",
      "]\n",
      "data_root = '/root/workspace/mmyolo/data/cat/'\n",
      "dataset_type = 'YOLOv5CocoDataset'\n",
      "deepen_factor = 0.67\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=10, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
      "default_scope = 'mmyolo'\n",
      "dsl_topk = 13\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_scale = (\n",
      "    640,\n",
      "    640,\n",
      ")\n",
      "img_scales = [\n",
      "    (\n",
      "        640,\n",
      "        640,\n",
      "    ),\n",
      "    (\n",
      "        320,\n",
      "        320,\n",
      "    ),\n",
      "    (\n",
      "        960,\n",
      "        960,\n",
      "    ),\n",
      "]\n",
      "launcher = 'none'\n",
      "load_from = 'work_dirs/rtmdet_m_syncbn_fast_8xb32-300e_coco/epoch_10.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "loss_bbox_weight = 2.0\n",
      "loss_cls_weight = 1.0\n",
      "lr_start_factor = 1e-05\n",
      "max_epochs = 10\n",
      "max_keep_ckpts = 3\n",
      "meta_info = dict(\n",
      "    classes=[\n",
      "        'cat',\n",
      "    ], palette=[\n",
      "        (\n",
      "            0,\n",
      "            0,\n",
      "            0,\n",
      "        ),\n",
      "    ])\n",
      "mixup_max_cached_images = 20\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        arch='P5',\n",
      "        channel_attention=True,\n",
      "        deepen_factor=0.67,\n",
      "        expand_ratio=0.5,\n",
      "        norm_cfg=dict(type='BN'),\n",
      "        type='CSPNeXt',\n",
      "        widen_factor=0.75),\n",
      "    bbox_head=dict(\n",
      "        bbox_coder=dict(type='DistancePointBBoxCoder'),\n",
      "        head_module=dict(\n",
      "            act_cfg=dict(inplace=True, type='SiLU'),\n",
      "            feat_channels=256,\n",
      "            featmap_strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            in_channels=256,\n",
      "            norm_cfg=dict(type='BN'),\n",
      "            num_classes=1,\n",
      "            pred_kernel_size=1,\n",
      "            share_conv=True,\n",
      "            stacked_convs=2,\n",
      "            type='RTMDetSepBNHeadModule',\n",
      "            widen_factor=0.75),\n",
      "        loss_bbox=dict(loss_weight=2.0, type='mmdet.GIoULoss'),\n",
      "        loss_cls=dict(\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='mmdet.QualityFocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        prior_generator=dict(\n",
      "            offset=0, strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ], type='mmdet.MlvlPointGenerator'),\n",
      "        type='RTMDetHead'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=False,\n",
      "        mean=[\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.12,\n",
      "            58.395,\n",
      "        ],\n",
      "        type='YOLOv5DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        deepen_factor=0.67,\n",
      "        expand_ratio=0.5,\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        norm_cfg=dict(type='BN'),\n",
      "        num_csp_blocks=3,\n",
      "        out_channels=256,\n",
      "        type='CSPNeXtPAFPN',\n",
      "        widen_factor=0.75),\n",
      "    test_cfg=dict(\n",
      "        max_per_img=300,\n",
      "        multi_label=True,\n",
      "        nms=dict(iou_threshold=0.65, type='nms'),\n",
      "        nms_pre=30000,\n",
      "        score_thr=0.001),\n",
      "    train_cfg=dict(\n",
      "        allowed_border=-1,\n",
      "        assigner=dict(\n",
      "            iou_calculator=dict(type='mmdet.BboxOverlaps2D'),\n",
      "            num_classes=1,\n",
      "            topk=13,\n",
      "            type='BatchDynamicSoftLabelAssigner'),\n",
      "        debug=False,\n",
      "        pos_weight=-1),\n",
      "    type='YOLODetector')\n",
      "model_test_cfg = dict(\n",
      "    max_per_img=300,\n",
      "    multi_label=True,\n",
      "    nms=dict(iou_threshold=0.65, type='nms'),\n",
      "    nms_pre=30000,\n",
      "    score_thr=0.001)\n",
      "mosaic_max_cached_images = 40\n",
      "norm_cfg = dict(type='BN')\n",
      "num_classes = 1\n",
      "num_epochs_stage2 = 20\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.004, type='AdamW', weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1000, start_factor=1e-05,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=5,\n",
      "        begin=5,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=10,\n",
      "        eta_min=0.0002,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "persistent_workers = True\n",
      "qfl_beta = 2.0\n",
      "random_resize_ratio_range = (\n",
      "    0.1,\n",
      "    2.0,\n",
      ")\n",
      "resume = False\n",
      "save_checkpoint_intervals = 10\n",
      "strides = [\n",
      "    8,\n",
      "    16,\n",
      "    32,\n",
      "]\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/test.json',\n",
      "        batch_shapes_cfg=dict(\n",
      "            batch_size=32,\n",
      "            extra_pad_ratio=0.5,\n",
      "            img_size=640,\n",
      "            size_divisor=32,\n",
      "            type='BatchShapePolicy'),\n",
      "        data_prefix=dict(img='images'),\n",
      "        data_root='/root/workspace/mmyolo/data/cat/',\n",
      "        metainfo=dict(classes=[\n",
      "            'cat',\n",
      "        ], palette=[\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'pad_param',\n",
      "                ),\n",
      "                type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='/root/workspace/mmyolo/data/cat/annotations/test.json',\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='mmdet.CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(scale=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='YOLOv5KeepRatioResize'),\n",
      "    dict(\n",
      "        allow_scale_up=False,\n",
      "        pad_val=dict(img=114),\n",
      "        scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='LetterResize'),\n",
      "    dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "            'pad_param',\n",
      "        ),\n",
      "        type='mmdet.PackDetInputs'),\n",
      "]\n",
      "train_ann_file = 'annotations/test.json'\n",
      "train_batch_size_per_gpu = 4\n",
      "train_cfg = dict(\n",
      "    dynamic_intervals=[\n",
      "        (\n",
      "            -10,\n",
      "            1,\n",
      "        ),\n",
      "    ],\n",
      "    max_epochs=10,\n",
      "    type='EpochBasedTrainLoop',\n",
      "    val_interval=10)\n",
      "train_data_prefix = 'images'\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    collate_fn=dict(type='yolov5_collate'),\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/test.json',\n",
      "        data_prefix=dict(img='images'),\n",
      "        data_root='/root/workspace/mmyolo/data/cat/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(classes=[\n",
      "            'cat',\n",
      "        ], palette=[\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                img_scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                max_cached_images=40,\n",
      "                pad_val=114.0,\n",
      "                type='Mosaic',\n",
      "                use_cached=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.1,\n",
      "                    2.0,\n",
      "                ),\n",
      "                resize_type='mmdet.Resize',\n",
      "                scale=(\n",
      "                    1280,\n",
      "                    1280,\n",
      "                ),\n",
      "                type='mmdet.RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='mmdet.RandomCrop'),\n",
      "            dict(type='mmdet.YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='mmdet.Pad'),\n",
      "            dict(max_cached_images=20, type='YOLOv5MixUp', use_cached=True),\n",
      "            dict(type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_num_workers = 10\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        img_scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        max_cached_images=40,\n",
      "        pad_val=114.0,\n",
      "        type='Mosaic',\n",
      "        use_cached=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        resize_type='mmdet.Resize',\n",
      "        scale=(\n",
      "            1280,\n",
      "            1280,\n",
      "        ),\n",
      "        type='mmdet.RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='mmdet.RandomCrop'),\n",
      "    dict(type='mmdet.YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "    dict(\n",
      "        pad_val=dict(img=(\n",
      "            114,\n",
      "            114,\n",
      "            114,\n",
      "        )),\n",
      "        size=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='mmdet.Pad'),\n",
      "    dict(max_cached_images=20, type='YOLOv5MixUp', use_cached=True),\n",
      "    dict(type='mmdet.PackDetInputs'),\n",
      "]\n",
      "train_pipeline_stage2 = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        resize_type='mmdet.Resize',\n",
      "        scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='mmdet.RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='mmdet.RandomCrop'),\n",
      "    dict(type='mmdet.YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
      "    dict(\n",
      "        pad_val=dict(img=(\n",
      "            114,\n",
      "            114,\n",
      "            114,\n",
      "        )),\n",
      "        size=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='mmdet.Pad'),\n",
      "    dict(type='mmdet.PackDetInputs'),\n",
      "]\n",
      "tta_model = dict(\n",
      "    tta_cfg=dict(max_per_img=300, nms=dict(iou_threshold=0.65, type='nms')),\n",
      "    type='mmdet.DetTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            640,\n",
      "                            640,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                640,\n",
      "                                640,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            320,\n",
      "                            320,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                320,\n",
      "                                320,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "                dict(\n",
      "                    transforms=[\n",
      "                        dict(scale=(\n",
      "                            960,\n",
      "                            960,\n",
      "                        ), type='YOLOv5KeepRatioResize'),\n",
      "                        dict(\n",
      "                            allow_scale_up=False,\n",
      "                            pad_val=dict(img=114),\n",
      "                            scale=(\n",
      "                                960,\n",
      "                                960,\n",
      "                            ),\n",
      "                            type='LetterResize'),\n",
      "                    ],\n",
      "                    type='Compose'),\n",
      "            ],\n",
      "            [\n",
      "                dict(prob=1.0, type='mmdet.RandomFlip'),\n",
      "                dict(prob=0.0, type='mmdet.RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='mmdet.LoadAnnotations', with_bbox=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_id',\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'scale_factor',\n",
      "                        'pad_param',\n",
      "                        'flip',\n",
      "                        'flip_direction',\n",
      "                    ),\n",
      "                    type='mmdet.PackDetInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_ann_file = 'annotations/test.json'\n",
      "val_batch_size_per_gpu = 32\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_data_prefix = 'images'\n",
      "val_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/test.json',\n",
      "        batch_shapes_cfg=dict(\n",
      "            batch_size=32,\n",
      "            extra_pad_ratio=0.5,\n",
      "            img_size=640,\n",
      "            size_divisor=32,\n",
      "            type='BatchShapePolicy'),\n",
      "        data_prefix=dict(img='images'),\n",
      "        data_root='/root/workspace/mmyolo/data/cat/',\n",
      "        metainfo=dict(classes=[\n",
      "            'cat',\n",
      "        ], palette=[\n",
      "            (\n",
      "                0,\n",
      "                0,\n",
      "                0,\n",
      "            ),\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='YOLOv5KeepRatioResize'),\n",
      "            dict(\n",
      "                allow_scale_up=False,\n",
      "                pad_val=dict(img=114),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='LetterResize'),\n",
      "            dict(_scope_='mmdet', type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                    'pad_param',\n",
      "                ),\n",
      "                type='mmdet.PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='YOLOv5CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=10,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='/root/workspace/mmyolo/data/cat/annotations/test.json',\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='mmdet.CocoMetric')\n",
      "val_interval_stage2 = 1\n",
      "val_num_workers = 10\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='mmdet.DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "weight_decay = 0.05\n",
      "widen_factor = 0.75\n",
      "work_dir = 'wk'\n",
      "\n",
      "05/01 16:53:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "05/01 16:53:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_load_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(NORMAL      ) PipelineSwitchHook                 \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_save_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loads checkpoint by local backend from path: work_dirs/rtmdet_m_syncbn_fast_8xb32-300e_coco/epoch_10.pth\n",
      "05/01 16:53:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/rtmdet_m_syncbn_fast_8xb32-300e_coco/epoch_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/01 16:53:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "05/01 16:53:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.000 0.000 0.000 -1.000 -1.000 0.000\n",
      "05/01 16:53:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [1/1]    coco/bbox_mAP: 0.0000  coco/bbox_mAP_50: 0.0000  coco/bbox_mAP_75: 0.0000  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: -1.0000  coco/bbox_mAP_l: 0.0000  data_time: 3.5099  time: 7.5723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command executed successfully\n"
     ]
    }
   ],
   "source": [
    "if test_option == '1' and test_type == '0':\n",
    "    %cd /root/workspace/mmyolo\n",
    "    %run ./test.ipynb\n",
    "    testing_image(MAX_EPOCHS, custom_config_file_path_base,test_images,test_json_relpath,dummy_config,metainfo,BATCH_SIZE,NUM_CLASSES,dataset_root)   \n",
    "    %cd /root/workspace/mmyolo\n",
    "    import subprocess\n",
    "    command_line = f\"python tools/test.py \\\n",
    "        configs/{selected_model_type}/{custom_config_file_path} \\\n",
    "        work_dirs/{custom_config_file_path_without_extension}/epoch_{MAX_EPOCHS}.pth \\\n",
    "        --work-dir wk\"\n",
    "\n",
    "    # Run the command\n",
    "    result = subprocess.run(command_line, shell=True)\n",
    "\n",
    "    # Check the result\n",
    "    if result.returncode == 0:\n",
    "        print(\"Command executed successfully\")\n",
    "    else:\n",
    "        print(f\"Error executing the command. Return code: {result.returncode}\")\n",
    "        print(f\"Output: {result.stdout}\")\n",
    "        print(f\"Error: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c4ca3-1d63-4f86-ad8c-6ebc6e178617",
   "metadata": {},
   "source": [
    "# testing with the trained model with video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "59cdaab8-d3ba-402d-a51f-0d4b93f62e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_option == '1' and test_type == '1':\n",
    "    print(\".....testing on video......\")\n",
    "    %cd /root/workspace/mmyolo\n",
    "    %run ./test.ipynb\n",
    "    testing_video(MAX_EPOCHS, custom_config_file_path_base,selected_model_type,video_path,output_path,custom_config_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40a503-1f99-437c-8434-a365ef35df44",
   "metadata": {},
   "source": [
    "# Quantize the model (convert the pytorch model into tensorrt model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab195c-8aa4-4145-bd7b-2d0d6a229afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmyolo\n",
      "........in quantize...........\n",
      "/root/workspace\n",
      "05/01 16:54:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Import mmdeploy.codebase.mmyolo.deploy failedPlease check whether the module is the custom module.No module named 'mmdeploy.codebase.mmyolo'\n",
      "05/01 16:54:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
      "05/01 16:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Start pipeline mmdeploy.apis.pytorch2onnx.torch2onnx in subprocess\n",
      "05/01 16:54:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Import mmdeploy.codebase.mmyolo.deploy failedPlease check whether the module is the custom module.No module named 'mmdeploy.codebase.mmyolo'\n",
      "05/01 16:54:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmyolo\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmyolo\" is a correct scope, or whether the registry is initialized.\n",
      "Loads checkpoint by local backend from path: mmyolo/work_dirs/rtmdet_m_syncbn_fast_8xb32-300e_coco/epoch_10.pth\n",
      "Switch model to deploy modality.\n",
      "05/01 16:54:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - DeprecationWarning: get_onnx_config will be deprecated in the future. \n",
      "05/01 16:54:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Export PyTorch model to ONNX: mmdeploy_model/rtmdet_m_syncbn_fast_8xb32-300e_coco.py_tensorrt/end2end.onnx.\n",
      "05/01 16:54:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Can not find torch.nn.functional.scaled_dot_product_attention, function rewrite will not be applied\n",
      "05/01 16:54:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Can not find torch._C._jit_pass_onnx_autograd_function_process, function rewrite will not be applied\n",
      "05/01 16:54:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Can not find torch._C._jit_pass_onnx_deduplicate_initializers, function rewrite will not be applied\n",
      "05/01 16:54:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Can not find mmdet.models.utils.transformer.PatchMerging.forward, function rewrite will not be applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of mmdeploy::TRTBatchedNMS type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of mmdeploy::TRTBatchedNMS type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of mmdeploy::TRTBatchedNMS type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of mmdeploy::TRTBatchedNMS type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of mmdeploy::TRTBatchedNMS type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of mmdeploy::TRTBatchedNMS type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/01 16:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Execute onnx optimize passes.\n",
      "05/01 16:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Finish pipeline mmdeploy.apis.pytorch2onnx.torch2onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/workspace/mmdeploy/mmdeploy/core/optimizers/function_marker.py:160: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  ys_shape = tuple(int(s) for s in ys.shape)\n",
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/root/workspace/mmyolo/mmyolo/models/task_modules/coders/distance_point_bbox_coder.py:45: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert points.size(-2) == pred_bboxes.size(-2)\n",
      "/root/workspace/mmyolo/mmyolo/models/task_modules/coders/distance_point_bbox_coder.py:46: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert points.size(-1) == 2\n",
      "/root/workspace/mmyolo/mmyolo/models/task_modules/coders/distance_point_bbox_coder.py:47: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert pred_bboxes.size(-1) == 4\n",
      "/root/workspace/mmdeploy/mmdeploy/mmcv/ops/nms.py:477: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  int(scores.shape[-1]),\n",
      "/root/workspace/mmdeploy/mmdeploy/mmcv/ops/nms.py:149: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  out_boxes = min(num_boxes, after_topk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/01 16:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Start pipeline mmdeploy.apis.utils.utils.to_backend in subprocess\n",
      "05/01 16:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Successfully loaded tensorrt plugins from /root/workspace/mmdeploy/mmdeploy/lib/libmmdeploy_tensorrt_ops.so\n",
      "[05/01/2024-16:54:29] [TRT] [I] [MemUsageChange] Init CUDA: CPU +605, GPU +0, now: CPU 690, GPU 256 (MiB)\n",
      "[05/01/2024-16:54:30] [TRT] [I] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 690 MiB, GPU 256 MiB\n",
      "[05/01/2024-16:54:30] [TRT] [I] [MemUsageSnapshot] End constructing builder kernel library: CPU 849 MiB, GPU 290 MiB\n",
      "[05/01/2024-16:54:30] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/01/2024-16:54:30] [TRT] [I] Input filename:   mmdeploy_model/rtmdet_m_syncbn_fast_8xb32-300e_coco.py_tensorrt/end2end.onnx\n",
      "[05/01/2024-16:54:30] [TRT] [I] ONNX IR version:  0.0.7\n",
      "[05/01/2024-16:54:30] [TRT] [I] Opset version:    11\n",
      "[05/01/2024-16:54:30] [TRT] [I] Producer name:    pytorch\n",
      "[05/01/2024-16:54:30] [TRT] [I] Producer version: 1.10\n",
      "[05/01/2024-16:54:30] [TRT] [I] Domain:           \n",
      "[05/01/2024-16:54:30] [TRT] [I] Model version:    0\n",
      "[05/01/2024-16:54:30] [TRT] [I] Doc string:       \n",
      "[05/01/2024-16:54:30] [TRT] [I] ----------------------------------------------------------------\n",
      "[05/01/2024-16:54:30] [TRT] [W] parsers/onnx/onnx2trt_utils.cpp:368: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[05/01/2024-16:54:32] [TRT] [I] No importer registered for op: TRTBatchedNMS. Attempting to import as plugin.\n",
      "[05/01/2024-16:54:32] [TRT] [I] Searching for plugin: TRTBatchedNMS, plugin_version: 1, plugin_namespace: \n",
      "[05/01/2024-16:54:32] [TRT] [I] Successfully created plugin: TRTBatchedNMS\n",
      "[05/01/2024-16:54:37] [TRT] [W] TensorRT was linked against cuBLAS/cuBLASLt 11.6.5 but loaded cuBLAS/cuBLASLt 11.5.1\n",
      "[05/01/2024-16:54:37] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +824, GPU +206, now: CPU 1795, GPU 496 (MiB)\n",
      "[05/01/2024-16:54:37] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +242, GPU +52, now: CPU 2037, GPU 548 (MiB)\n",
      "[05/01/2024-16:54:37] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n"
     ]
    }
   ],
   "source": [
    "if quantize_option == '1':\n",
    "    %cd /root/workspace/mmyolo\n",
    "    %run ./quantize.ipynb\n",
    "    quantize(quantize_option, quantize_bits, batch_size_choice)\n",
    "    import subprocess\n",
    "    %cd /root/workspace/\n",
    "    command_line = f\"python mmdeploy/tools/deploy.py \\\n",
    "    /root/workspace/mmyolo/configs/deploy/detection_tensorrt_dynamic-192x192-960x960.py \\\n",
    "    {config_file_path} \\\n",
    "    mmyolo/work_dirs/{custom_config_file_path_without_extension}/epoch_{MAX_EPOCHS}.pth \\\n",
    "    mmyolo/demo/demo.jpg \\\n",
    "    --work-dir mmdeploy_model/{custom_config_file_path}_tensorrt \\\n",
    "    --device cuda \\\n",
    "    --dump-info\"\n",
    "\n",
    "    # Run the command\n",
    "    result = subprocess.run(command_line, shell=True)\n",
    "\n",
    "    # Check the result\n",
    "    if result.returncode == 0:\n",
    "        print(\"Command executed successfully\")\n",
    "    else:\n",
    "        print(f\"Error executing the command. Return code: {result.returncode}\")\n",
    "        print(f\"Output: {result.stdout}\")\n",
    "        print(f\"Error: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acc9e2-9126-4612-b188-684bf91c0682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42548165-5070-4363-946e-8a6df4759ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
