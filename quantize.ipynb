{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dac21ae-4af8-4bb2-9cdf-a919cff6af16",
   "metadata": {},
   "source": [
    "# quantize with the trained pytorch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00388206-979c-4c4c-b33f-d010e55f1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python mmdeploy/tools/deploy.py \\\n",
    "    # mmyolo/configs/deploy/detection_tensorrt_dynamic-192x192-960x960.py \\\n",
    "    # {custom_config_file_path} \\\n",
    "    # ../mmyolo/work_dirs/{custom_config_file_path} \\\n",
    "    # ../datasets/clean_dataset/test_data/10_001.jpg \\\n",
    "    # --work-dir mmdeploy_model/RTM-tiny-fp32_batch_16 \\\n",
    "    # --device cuda \\\n",
    "    # --dump-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4337db5-6abb-4457-bfee-8821a0042c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(quantize_option, quantize_bits, batch_size_choice):\n",
    "    import os\n",
    "    print('........in quantize...........')\n",
    "    # Change directory to the specified path\n",
    "    if quantize_option == '1' and quantize_bits == '0':\n",
    "        custom_config = '/root/workspace/mmyolo/configs/deploy/custom_config.py'\n",
    "        deploy_config = '/root/workspace/mmyolo/configs/deploy/detection_tensorrt_dynamic-192x192-960x960.py'\n",
    "        \n",
    "        with open(custom_config, 'r') as f:\n",
    "            custom_cfg_content = f.read()\n",
    "            custom_cfg_content = custom_cfg_content.replace(\"fp16_mode=\", \"fp16_mode=True\")\n",
    "            \n",
    "            if batch_size_choice == '0':\n",
    "                batch_size_choice_value = '1'\n",
    "            elif batch_size_choice == '1':\n",
    "                batch_size_choice_value = '2'\n",
    "            elif batch_size_choice == '2':\n",
    "                batch_size_choice_value = '4'\n",
    "            elif batch_size_choice == '3':\n",
    "                batch_size_choice_value = '8'\n",
    "            else:\n",
    "                batch_size_choice_value = '16'\n",
    "\n",
    "            custom_cfg_content = custom_cfg_content.replace(\n",
    "                \"min_shape=[batch_size_choice, 3, 192, 192]\",\n",
    "                f\"min_shape=[{batch_size_choice_value}, 3, 192, 192]\"\n",
    "            )\n",
    "            custom_cfg_content = custom_cfg_content.replace(\n",
    "                \"opt_shape=[batch_size_choice, 3, 640, 640]\",\n",
    "                f\"opt_shape=[{batch_size_choice_value}, 3, 640, 640]\"\n",
    "            )\n",
    "            custom_cfg_content = custom_cfg_content.replace(\n",
    "                \"max_shape=[batch_size_choice, 3, 960, 960]\",\n",
    "                f\"max_shape=[{batch_size_choice_value}, 3, 960, 960]\"\n",
    "            )\n",
    "\n",
    "        with open(deploy_config, 'w') as f:\n",
    "            f.write(custom_cfg_content)\n",
    "\n",
    "    elif quantize_option == '1' and quantize_bits == '1':\n",
    "        custom_config = '../mmyolo/configs/deploy/custom_config.py'\n",
    "        deploy_config = '../mmyolo/configs/deploy/detection_tensorrt_dynamic-192x192-960x960.py'\n",
    "        \n",
    "        with open(custom_config, 'r') as f:\n",
    "            custom_cfg_content = f.read()\n",
    "            custom_cfg_content = custom_cfg_content.replace(\"fp16_mode=\", \"fp16_mode=False\")\n",
    "            \n",
    "            if batch_size_choice == '0':\n",
    "                batch_size_choice_value = '1'\n",
    "            elif batch_size_choice == '1':\n",
    "                batch_size_choice_value = '2'\n",
    "            elif batch_size_choice == '2':\n",
    "                batch_size_choice_value = '4'\n",
    "            elif batch_size_choice == '3':\n",
    "                batch_size_choice_value = '8'\n",
    "            else:\n",
    "                batch_size_choice_value = '16'\n",
    "\n",
    "            custom_cfg_content = custom_cfg_content.replace(\n",
    "                \"min_shape=[batch_size_choice, 3, 192, 192]\",\n",
    "                f\"min_shape=[{batch_size_choice_value}, 3, 192, 192]\"\n",
    "            )\n",
    "            custom_cfg_content = custom_cfg_content.replace(\n",
    "                \"opt_shape=[batch_size_choice, 3, 640, 640]\",\n",
    "                f\"opt_shape=[{batch_size_choice_value}, 3, 640, 640]\"\n",
    "            )\n",
    "            custom_cfg_content = custom_cfg_content.replace(\n",
    "                \"max_shape=[batch_size_choice, 3, 960, 960]\",\n",
    "                f\"max_shape=[{batch_size_choice_value}, 3, 960, 960]\"\n",
    "            )\n",
    "\n",
    "        with open(deploy_config, 'w') as f:\n",
    "            f.write(custom_cfg_content)\n",
    "    \n",
    "# Example usage\n",
    "# quantize_option = '1'\n",
    "# quantize_bits = '1'\n",
    "# batch_size_choice = '2'\n",
    "# MAX_EPOCHS = 100\n",
    "# # config_file_path = '/path/to/your/config/file.py'\n",
    "\n",
    "# quantize(quantize_option, quantize_bits, batch_size_choice, MAX_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95e81c-c4ff-40a2-a153-69f592a843e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
