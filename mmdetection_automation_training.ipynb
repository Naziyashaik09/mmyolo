{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f455b84-3f4b-4f22-aa23-ad532b7d11e1",
   "metadata": {},
   "source": [
    "# Enter the dataset paths , the percentage for the data split and the parameters to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead2554-8922-48af-bc3d-ef16d064d215",
   "metadata": {},
   "source": [
    "### Before starting , once refer the readme.md file in the location \"/home/viso/sample_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c216133-47ec-4356-8da3-e8e9ea85bf4a",
   "metadata": {},
   "source": [
    "# If you want to download the predefined dataset follow the next 2 steps or else you can skip that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9926dcf7-c75a-4f08-a0d0-c0c0df58faa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://download.openmmlab.com/mmyolo/data/cat_dataset.zip to data/cat/cat_dataset.zip\n",
      "100%|████████████████████████████████████████| 217M/217M [00:46<00:00, 4.87MB/s]\n",
      "Unzipping cat_dataset.zip\n",
      "Delete data/cat/cat_dataset.zip\n"
     ]
    }
   ],
   "source": [
    "!python3 tools/misc/download_dataset.py --dataset-name cat --save-dir ./data/cat --unzip --delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d6468b-8da5-4d58-8ef8-37d0c4e216c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations_all.json  test.json  trainval.json\n"
     ]
    }
   ],
   "source": [
    "ls data/cat/annotations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d982c8df-5521-4ff2-9319-2f076e1d4665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/teric/Downloads/mmyolo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86f2872-a88c-40c6-beab-672c0ea28dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### dataset_root is the path , where images and the annotation file consists \n",
    "dataset_root=input('Enter the dataset root path')\n",
    "\n",
    "# annotation_path , where there is a single file annotation in the coco (json) format \n",
    "annotation_path=input('Enter the annotation path ,(json file)')\n",
    "\n",
    "# consists of images for \n",
    "images=input('Enter the path where images are there ,(excluding the dataset_root path )')\n",
    "\n",
    "# The percentages are given to seperate the data into 3 parts (train , test and validation )\n",
    "train_percentage=input('Enter the percentage to divide the train dataset . Eg:0.8')\n",
    "test_percentage= input('Enter the percentage to divide the test dataset . Eg:0.1')\n",
    "val_percentage= input('Enter the percentage to divide the validation dataset . Eg:0.1')\n",
    "\n",
    "# enter the epochs , upto how much epochs the models needs to train \n",
    "MAX_EPOCHS = input('Enter the MAX_EPOCHS ')\n",
    "\n",
    "# BATCH_SIZE means  \"The number of training examples utilized in one iteration\".\n",
    "BATCH_SIZE = input('Enter the BATCH_SIZE')\n",
    "\n",
    "#\"Num classes\" simply means the number of different categories in the dataset\n",
    "# NUM_CLASSES = input('Enter the NUM_CLASSES ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6373b-a8bb-4491-a1c4-74bc87e31066",
   "metadata": {},
   "source": [
    "# select the model , need to do testing and quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc73310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a model type:\n",
      "0. YOLOx\n",
      "1. RTMDET\n",
      "2. YOLOv7\n",
      "Please select a RTMDET model variant:\n",
      "0. rtmdet_tiny\n",
      "1. rtmdet_s\n",
      "2. rtmdet_l\n",
      "3. rtmdet_m\n",
      "4. rtmdet_x\n",
      "You selected: rtmdet_l\n",
      "Please specify whether you want to enable or disable each augmentation option (0 for False, 1 for True):\n",
      "Choose batch size:\n",
      "0. 1\n",
      "1. 2\n",
      "2. 4\n",
      "3. 8\n",
      "4. 16\n",
      "You selected: rtmdet_l\n",
      "Testing option: yes\n",
      "Testing on: video at path: None\n",
      "Quantize option: yes\n",
      "Quantization precision: fp32\n",
      "Batch size: 4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Dictionary of model types and their corresponding options\n",
    "model_types = {\n",
    "    \"YOLOx\": [\"yolox_tiny\", \"yolox_s\", \"yolox_m\", \"yolox_l\", \"yolox_x\"],\n",
    "    \"RTMDET\": [\"rtmdet_tiny\", \"rtmdet_s\", \"rtmdet_l\", \"rtmdet_m\", \"rtmdet_x\"],\n",
    "    \"YOLOv7\": [\"yolov7_tiny\", \"yolov7_l\", \"yolov7_x\", \"yolov7_w\", \"yolov7_e\"],\n",
    "}\n",
    "\n",
    "# Batch size options\n",
    "batch_size_options = [1, 2, 4, 8, 16]\n",
    "\n",
    "# Variable to store user's choice\n",
    "selected_model_type = None\n",
    "selected_model_variant = None\n",
    "test_option = None\n",
    "path = None\n",
    "quantize_option = None\n",
    "quantize_bits = None\n",
    "batch_size = None\n",
    "AUGMENTATIONS = {\n",
    "    \"noise\": False,\n",
    "    \"denoise\": False,\n",
    "    \"contrast\": False,\n",
    "    \"brightness\": False,\n",
    "    \"rotation\": False\n",
    "}\n",
    "# Print model types\n",
    "print(\"Please select a model type:\")\n",
    "for i, model_type in enumerate(model_types):\n",
    "    print(f\"{i}. {model_type}\")\n",
    "\n",
    "# Get input for model type\n",
    "while True:\n",
    "    model_type_choice = input(\"Enter choice (0-{}): \".format(len(model_types) - 1))\n",
    "    try:\n",
    "        model_type_choice = int(model_type_choice)\n",
    "        if 0 <= model_type_choice < len(model_types):\n",
    "            selected_model_type = list(model_types.keys())[model_type_choice]\n",
    "            break\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    print(\"Invalid choice, please try again\")\n",
    "\n",
    "# Print model variants for the selected model type\n",
    "print(f\"Please select a {selected_model_type} model variant:\")\n",
    "for i, model_variant in enumerate(model_types[selected_model_type]):\n",
    "    print(f\"{i}. {model_variant}\")\n",
    "\n",
    "# Get input for model variant\n",
    "while True:\n",
    "    model_variant_choice = input(\"Enter choice (0-{}): \".format(len(model_types[selected_model_type]) - 1))\n",
    "    try:\n",
    "        model_variant_choice = int(model_variant_choice)\n",
    "        if 0 <= model_variant_choice < len(model_types[selected_model_type]):\n",
    "            selected_model_variant = model_types[selected_model_type][model_variant_choice]\n",
    "            break\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    print(\"Invalid choice, please try again\")\n",
    "\n",
    "print(f\"You selected: {selected_model_variant}\")\n",
    "# Ask if the user wants to train the model with data augmentation\n",
    "while True:\n",
    "    train_with_augmentation = input(\"Do you want to train the model with data augmentation? (0 for no, 1 for yes): \")\n",
    "    if train_with_augmentation in [\"0\", \"1\"]:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "if train_with_augmentation == \"1\":\n",
    "    print(\"Please specify whether you want to enable or disable each augmentation option (0 for False, 1 for True):\")\n",
    "    for augmentation, enabled in AUGMENTATIONS.items():\n",
    "        while True:\n",
    "            choice = input(f\"Do you want to enable {augmentation.capitalize()}? (0 for False, 1 for True): \")\n",
    "            if choice in [\"0\", \"1\"]:\n",
    "                AUGMENTATIONS[augmentation] = choice == \"1\"\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "# Ask if the user wants to test\n",
    "while True:\n",
    "    test_option = input(\"Do you need to test? (0 for no, 1 for yes): \")\n",
    "    if test_option in [\"0\", \"1\"]:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "\n",
    "# If testing is required, ask for image or video and corresponding path\n",
    "if test_option == \"1\":\n",
    "    while True:\n",
    "        test_type = input(\"Do you want to test on an image or a video? (0 for image, 1 for video): \")\n",
    "        if test_type == \"0\":\n",
    "            path = ''  # You can set a default value or leave it empty for images\n",
    "            break\n",
    "        elif test_type == \"1\":\n",
    "            video_path = input(\"Enter the video path: \")\n",
    "            output_path = input(\"Enter the path to save the video: \")\n",
    "\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "\n",
    "# Now 'path' will be either an empty string for images or the user-provided video path for videos\n",
    "\n",
    "# Ask if the user wants to quantize the model\n",
    "while True:\n",
    "    quantize_option = input(\"Do you want to quantize the model? (0 for no, 1 for yes): \")\n",
    "    if quantize_option in [\"0\", \"1\"]:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "\n",
    "# If quantizing is required, ask for the quantization bit precision\n",
    "if quantize_option == \"1\":\n",
    "    while True:\n",
    "        quantize_bits = input(\"Choose quantization precision (0 for fp16, 1 for fp32): \")\n",
    "        if quantize_bits in [\"0\", \"1\"]:\n",
    "            if quantize_bits == \"0\" or quantize_bits == \"1\":\n",
    "                while True:\n",
    "                    print(\"Choose batch size:\")\n",
    "                    for i, size in enumerate(batch_size_options):\n",
    "                        print(f\"{i}. {size}\")\n",
    "\n",
    "                    batch_size_choice = input(\"Enter choice (0-{}): \".format(len(batch_size_options) - 1))\n",
    "                    try:\n",
    "                        batch_size_choice = int(batch_size_choice)\n",
    "                        if 0 <= batch_size_choice < len(batch_size_options):\n",
    "                            batch_size = batch_size_options[batch_size_choice]\n",
    "                            break\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                    print(\"Invalid choice, please try again.\")\n",
    "\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice, please enter '0' or '1'.\")\n",
    "\n",
    "print(f\"You selected: {selected_model_variant}\")\n",
    "print(f\"Testing option: {'yes' if test_option == '1' else 'no'}\")\n",
    "if test_option == \"1\":\n",
    "    print(f\"Testing on: {'image' if test_type == '0' else 'video'} at path: {path}\")\n",
    "print(f\"Quantize option: {'yes' if quantize_option == '1' else 'no'}\")\n",
    "if quantize_option == \"1\":\n",
    "    print(f\"Quantization precision: {'fp16' if quantize_bits == '0' else 'fp32'}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cd8e46-52c5-4539-9d34-38c1bf7e9465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/teric/Downloads/mmyolo/data/cat/annotations'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "parent_directory = os.path.dirname(annotation_path)\n",
    "parent_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7840c0bc-1517-4232-834e-de96358f2614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noise': False,\n",
       " 'denoise': False,\n",
       " 'contrast': False,\n",
       " 'brightness': True,\n",
       " 'rotation': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ba3dfe-ab76-4945-ac49-f9a64742e23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_with_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59dbf36c-ce77-4bdd-99e9-a532a3dd5707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/teric/Downloads/mmyolo/data/cat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125dd5c8-4717-4850-85da-5862e39a230c",
   "metadata": {},
   "source": [
    "# Generating metainfo for the config based on the annotation file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a1b83e-f5ac-4274-a390-315bc8ba32be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names: ['cat']\n",
      "Number of Classes: 1\n",
      "Metainfo: {'classes': ['cat'], 'palette': [(0, 0, 0)]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(annotation_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "classes = [c['name'] for c in data['categories']]\n",
    "NUM_CLASSES = len(classes)\n",
    "palette = []\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    r = (i * 50) % 255\n",
    "    g = (i * 100) % 255\n",
    "    b = (i * 150) % 255\n",
    "    palette.append((r, g, b))\n",
    "\n",
    "metainfo = {\n",
    "    'classes': classes,\n",
    "    'palette': palette\n",
    "}\n",
    "class_names=metainfo['classes']\n",
    "print(\"Class Names:\", class_names)\n",
    "print(\"Number of Classes:\", NUM_CLASSES)\n",
    "print(\"Metainfo:\", metainfo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a5a75d-6110-47eb-b53b-31fd3481e817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c1afd-9791-4639-b3f5-f250555d9144",
   "metadata": {},
   "source": [
    "# Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057d901-bc51-408c-b982-83f9121b146a",
   "metadata": {},
   "source": [
    "# converting the annotations from json to txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e2db8f-c315-412d-b9f8-cf201eca6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "# Load COCO annotations \n",
    "def convert_coco_to_yolo_old(annotation_path,dataset_root):\n",
    "    print(\".......... in convert_coco_to_yolo ..........\")\n",
    "    print(annotation_path)\n",
    "    # Ensure the \"txt_files\" directory exists or create it\n",
    "    txt_files_dir = os.path.join(dataset_root, 'txt_files')\n",
    "    print(txt_files_dir)\n",
    "    if not os.path.exists(txt_files_dir):\n",
    "        os.makedirs(txt_files_dir)\n",
    "\n",
    "    with open(annotation_path) as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "\n",
    "    # Create lists to store image info and annotations\n",
    "    image_ids = []\n",
    "    image_info = []\n",
    "    annotations = []\n",
    "    print(\"image_ids\",image_ids)\n",
    "    print(\"image_info\",image_info)\n",
    "    print(\"annotations\",annotations)\n",
    "    # Get image ids and image info \n",
    "    for img in coco['images']:\n",
    "        image_ids.append(img['id'])\n",
    "        image_info.append({'file_name': img['file_name'],\n",
    "                           'width': img['width'],\n",
    "                           'height': img['height']})\n",
    "        # print(\"image id are\",image_ids)\n",
    "    # print(\".........................\")\n",
    "    # Get annotations \n",
    "    for ann in coco['annotations']:\n",
    "        bbox = ann['bbox']\n",
    "        x, y, width, height = bbox\n",
    "        image_id = ann['image_id']\n",
    "        category_id = ann['category_id']\n",
    "        # print(\"image id 'ssssssssss\",image_id)\n",
    "        # Convert to relative cooridnates \n",
    "        x_rel = x/image_info[image_id-1]['width'] \n",
    "        y_rel = y/image_info[image_id-1]['height']\n",
    "        width_rel = width/image_info[image_id-1]['width']\n",
    "        height_rel = height/image_info[image_id-1]['height']\n",
    "\n",
    "        annotation = (category_id, x_rel, y_rel, width_rel, height_rel)\n",
    "        annotations.append({'image_id': image_id, 'annotation': annotation})\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    yolo_annotations = []\n",
    "    for annotation in annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        # print(\"image_id\",image_id)\n",
    "        category_id, x, y, width, height = annotation['annotation']\n",
    "\n",
    "        # Calculate center x, y \n",
    "        x_center = x + width/2\n",
    "        y_center = y + height/2\n",
    "\n",
    "        yolo_annotation = f\"{category_id} {x_center} {y_center} {width} {height}\\n\"\n",
    "        yolo_annotations.append({'image_id': image_id, 'annotation': yolo_annotation})\n",
    "\n",
    "    # Group annotations by image    \n",
    "    yolo_files = {}\n",
    "    for annotation in yolo_annotations:\n",
    "        print(yolo_annotations)\n",
    "        image_id = annotation['image_id']\n",
    "        yolo_annotation = annotation['annotation']\n",
    "        if image_id not in yolo_files:\n",
    "            yolo_files[image_id] = [yolo_annotation]\n",
    "        else:\n",
    "            yolo_files[image_id].append(yolo_annotation)\n",
    "\n",
    "\n",
    "    # Save annotation files\n",
    "        for image_id, annotations in yolo_files.items(): \n",
    "            file_name = image_info[image_id-1]['file_name']\n",
    "            # print('.1.',file_name)\n",
    "            file_name = file_name.split('.')[0] + '.txt'\n",
    "            # print('.2.',file_name)\n",
    "            base_name = os.path.splitext(os.path.basename(file_name))[0]  # Get the base name without extension\n",
    "\n",
    "            # Construct the destination .txt file name\n",
    "            txt_file_name = base_name + '.txt'\n",
    "            file_path = os.path.join(txt_files_dir, txt_file_name)\n",
    "\n",
    "            #print(f\"Saving to: {file_path}\")\n",
    "\n",
    "            with open(file_path, 'w') as f:\n",
    "            # with open(txt_files_dir, 'w') as f:\n",
    "                for annotation in annotations:\n",
    "                    f.write(annotation)\n",
    "\n",
    "            # with open(file_path, 'w') as f:\n",
    "            #     for annotation in annotations:\n",
    "            #         f.write(annotation + '\\n')\n",
    "            #         # destination_path = os.path.join(txt_files_dir, file_name)\n",
    "            #         shutil.move(file_path, txt_files_dir)\n",
    "\n",
    "\n",
    "\n",
    "    # Save image list file\n",
    "    # with open('train.txt', 'w') as f:\n",
    "    #     for image_id in image_ids:\n",
    "    #         file_name = image_info[image_id-1]['file_name']\n",
    "    #         f.write(file_name + '\\n')\n",
    "    \n",
    "#convert_coco_to_yolo(annotation_path, dataset_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ced0d4e-d85e-4576-abaa-10428cc40e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def convert_coco_to_yolo(annotation_path, dataset_root):\n",
    "    print(\".......... in convert_coco_to_yolo ..........\")\n",
    "    print(annotation_path)\n",
    "\n",
    "    # Ensure the \"txt_files\" directory exists or create it\n",
    "    txt_files_dir = os.path.join(dataset_root, 'txt_files')\n",
    "    print(txt_files_dir)\n",
    "    if not os.path.exists(txt_files_dir):\n",
    "        os.makedirs(txt_files_dir)\n",
    "\n",
    "    with open(annotation_path) as f:\n",
    "        coco = json.load(f)\n",
    "\n",
    "    # Create lists to store image info and annotations\n",
    "    image_info = {}\n",
    "    annotations = []\n",
    "\n",
    "    # Get image info\n",
    "    for img in coco['images']:\n",
    "        image_info[img['id']] = {'file_name': img['file_name'],\n",
    "                                  'width': img['width'],\n",
    "                                  'height': img['height']}\n",
    "\n",
    "    # Get annotations \n",
    "    for ann in coco['annotations']:\n",
    "        bbox = ann['bbox']\n",
    "        x, y, width, height = bbox\n",
    "        image_id = ann['image_id']\n",
    "        if image_id not in image_info:\n",
    "            print(f\"Warning: Image ID {image_id} not found in image info\")\n",
    "            continue\n",
    "\n",
    "        category_id = ann['category_id']\n",
    "        \n",
    "        # Convert to relative coordinates \n",
    "        x_rel = x / image_info[image_id]['width']\n",
    "        y_rel = y / image_info[image_id]['height']\n",
    "        width_rel = width / image_info[image_id]['width']\n",
    "        height_rel = height / image_info[image_id]['height']\n",
    "\n",
    "        annotation = (category_id, x_rel, y_rel, width_rel, height_rel)\n",
    "        annotations.append({'image_id': image_id, 'annotation': annotation})\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    yolo_annotations = []\n",
    "    for annotation in annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        category_id, x, y, width, height = annotation['annotation']\n",
    "\n",
    "        # Calculate center x, y \n",
    "        x_center = x + width / 2\n",
    "        y_center = y + height / 2\n",
    "\n",
    "        yolo_annotation = f\"{category_id} {x_center} {y_center} {width} {height}\\n\"\n",
    "        yolo_annotations.append({'image_id': image_id, 'annotation': yolo_annotation})\n",
    "\n",
    "    # Group annotations by image    \n",
    "    yolo_files = {}\n",
    "    for annotation in yolo_annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        yolo_annotation = annotation['annotation']\n",
    "        if image_id not in yolo_files:\n",
    "            yolo_files[image_id] = [yolo_annotation]\n",
    "        else:\n",
    "            yolo_files[image_id].append(yolo_annotation)\n",
    "\n",
    "    # Save annotation files\n",
    "    for image_id, annotations in yolo_files.items(): \n",
    "        if image_id not in image_info:\n",
    "            print(f\"Error: Image ID {image_id} not found in image info\")\n",
    "            continue\n",
    "            \n",
    "        file_name = image_info[image_id]['file_name']\n",
    "        base_name = os.path.splitext(os.path.basename(file_name))[0]  # Get the base name without extension\n",
    "        txt_file_name = base_name + '.txt'\n",
    "        file_path = os.path.join(txt_files_dir, txt_file_name)\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            for annotation in annotations:\n",
    "                f.write(annotation)\n",
    "\n",
    "    # Save image list file\n",
    "    # with open('train.txt', 'w') as f:\n",
    "    #     for image_id in image_ids:\n",
    "    #         file_name = image_info[image_id-1]['file_name']\n",
    "    #         f.write(file_name + '\\n')\n",
    "\n",
    "# Now let's call the function\n",
    "# annotation_path = \"/home/viso/sample_data/annotations/total_annotations.json\"\n",
    "# dataset_root = \"/home/viso/sample_data/augmented_images\"\n",
    "# convert_coco_to_yolo(annotation_path, dataset_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0b864-c976-4340-aa47-58a5e33d3a72",
   "metadata": {},
   "source": [
    "# creating the config file for the data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16606162-77b5-4703-8848-403194b84f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_and_save_config(images, dataset_root,AUGMENTATIONS):\n",
    "    print(\"............edit_and_save_config..............\")\n",
    "    # %cd /home/viso/datasets/enhance_script\n",
    "    import json\n",
    "    new_config_path = '/root/workspace/mmyolo/quantize/dataset_enhance_config.json'\n",
    "    original_config_path = '/root/workspace/mmyolo/quantize/dataset_enhance_config-dummy.json'\n",
    "    # Load the original config\n",
    "    with open(original_config_path) as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    # Modify the content as needed\n",
    "    config[\"original_image_folder\"] = f'{dataset_root}/{images}'\n",
    "    config[\"original_label_folder\"] = f'{dataset_root}/txt_files'\n",
    "    config[\"enhance_image_folder\"] = f'{dataset_root}/train'\n",
    "    config[\"enhance_label_folder\"] = f'{dataset_root}/train'\n",
    "    config[\"augmentations\"] = {\n",
    "        \"noise\": AUGMENTATIONS['noise'],\n",
    "        \"denoise\": AUGMENTATIONS['denoise'],\n",
    "        \"contrast\": AUGMENTATIONS['contrast'],\n",
    "        \"brightness\": AUGMENTATIONS['brightness'],\n",
    "        \"rotation\": AUGMENTATIONS['rotation']\n",
    "    }\n",
    "    # Save the modified config to a new file\n",
    "    with open(new_config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# random_middle_part = 'images'\n",
    "# dataset_root = '/home/viso/sample_dataset'  # Provide the actual path\n",
    "# edit_and_save_config(original_config_path, new_config_path, random_middle_part, dataset_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba6bb0-02f1-45f7-9263-cdeb04c10893",
   "metadata": {},
   "source": [
    "# Getting all the image_paths in the txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb9a9a2-48c3-4777-a1b1-672c853c256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_image_paths(folder_path, extensions=[\".jpg\", \".png\"]):\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    return image_paths\n",
    "\n",
    "def write_paths_to_file(image_paths, output_file=f\"{dataset_root}/train.txt\"):\n",
    "    with open(output_file, \"w\") as file:\n",
    "        for path in image_paths:\n",
    "            file.write(path + \"\\n\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# folder_path = \"/home/viso/sample_data/augmented_imagges\"  # Replace with the actual path to your folder\n",
    "    # image_paths = get_image_paths(folder_path)\n",
    "    # write_paths_to_file(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcf5beb9-8b91-4941-9bbd-fa2751095a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def update_config_with_class_names(class_names):\n",
    "    dummy_main = '/root/workspace/mmyolo/quantize/dummy_main.py'\n",
    "    main='/root/workspace/mmyolo/quantize/main.py'\n",
    "    with open(dummy_main, 'r') as f:\n",
    "        cfg_content = f.read()\n",
    "\n",
    "    # Replace specific lines with new values\n",
    "    cfg_content = cfg_content.replace(\"classes =\", f\"classes = {class_names}\")\n",
    "\n",
    "    # Write the updated content back to the configuration file\n",
    "    with open(main, 'w') as custom_cfg_file:\n",
    "        custom_cfg_file.write(cfg_content)\n",
    "\n",
    "# Example usage:\n",
    "# number_of_classes = 10  # Replace with the actual number of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b330aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if train_with_augmentation=='1':\n",
    "    # %cd /home/viso/notebooks\n",
    "    # %run ./aug.ipynb\n",
    "    convert_coco_to_yolo(annotation_path, dataset_root)\n",
    "    edit_and_save_config(images, dataset_root,AUGMENTATIONS)\n",
    "    %cd /root/workspace/mmyolo/quantize\n",
    "    !python run_dataset_enhance.py\n",
    "    # %cd /home/viso/github/Yolo-to-COCO-format-converter\n",
    "    update_config_with_class_names(class_names)\n",
    "    !mkdir output\n",
    "    !pip install imagesize\n",
    "    !python main.py --path {dataset_root} --output output_json.json\n",
    "    %pwd\n",
    "    shutil.copy('/root/workspace/mmyolo/quantize/output/output_json.json',parent_directory)\n",
    "    %cd {dataset_root}\n",
    "    folder_path=f'{dataset_root}/train'\n",
    "    image_paths = get_image_paths(folder_path)\n",
    "    write_paths_to_file(image_paths)\n",
    "    with open('object.names', 'w') as f:\n",
    "        for class_name in class_names:\n",
    "            f.write(class_name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c9457-ac5f-47e6-b665-b3e671aabab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_with_augmentation=='1':\n",
    "    annotation_path = f'{parent_directory}/output_json.json'\n",
    "    print(annotation_path)\n",
    "    images = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7381d75-7922-4a96-9638-8d63c026b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(AUGMENTATIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210a761-5947-4ba5-bbf4-4f2236e69e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATIONS['noise']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6649f31-69dd-4902-b18d-af266a872d43",
   "metadata": {},
   "source": [
    "# split the annotation file into train , test and validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5add7c-530d-4662-9ea9-923c50fda5c6",
   "metadata": {},
   "source": [
    "### If there is single annotation file , that can divide into train , test and validation (coco format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e8f58-6f33-4fb1-b990-911115a341d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ea6ad-a89d-45b5-a11a-b570eb70fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sklearn\n",
    "!pip install funcy\n",
    "!pip install argparse\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e7465-4395-4df5-a252-4e83245ceda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/workspace/mmyolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf50abe-116d-476b-bb6b-e8a98532582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cocosplit_train_test_valid.py \\\n",
    "    --annotations \"{annotation_path}\" \\\n",
    "    --train_ratio {train_percentage} \\\n",
    "    --valid_ratio {val_percentage} \\\n",
    "    --test_ratio {test_percentage} \\\n",
    "    --trainJson_name train.json \\\n",
    "    --validJson_name val.json \\\n",
    "    --testJson_name test.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bed4fc-05c2-4fce-831e-774a57c5e29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379527e5-90ea-43fa-90d3-9a7ee8705c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , shutil\n",
    "# dataset_root = '/home/viso/datasets/viso_datasets/construction-demo'\n",
    "\n",
    "# parent_directory = os.path.dirname(annotation_path)\n",
    "shutil.copy('/root/workspace/mmyolo/test.json',parent_directory)\n",
    "shutil.copy('/root/workspace/mmyolo/val.json',parent_directory)\n",
    "shutil.copy('/root/workspace/mmyolo/train.json',parent_directory)\n",
    "\n",
    "train_json = os.path.join(parent_directory, 'train.json')\n",
    "val_json = os.path.join(parent_directory, 'val.json')\n",
    "test_json = os.path.join(parent_directory, 'test.json')\n",
    "\n",
    "# Remove the dataset_root prefix using os.path.relpath\n",
    "train_json_relpath = os.path.relpath(train_json, dataset_root)\n",
    "val_json_relpath = os.path.relpath(val_json, dataset_root)\n",
    "test_json_relpath = os.path.relpath(test_json, dataset_root)\n",
    "\n",
    "print(train_json_relpath, val_json_relpath, test_json_relpath)\n",
    "print(parent_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d964eb5-bb9f-4b6c-8307-3194f9d7ac3f",
   "metadata": {},
   "source": [
    "# Yolox configuration setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc5ce8-a5fa-40f3-9bb5-cb7a6e30ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the selected model type is 'YOLOx'\n",
    "if selected_model_type == 'YOLOx':\n",
    "    # Provide the path to the user for modification\n",
    "    dummy_config = '/root/workspace/mmyolo/configs/yolox/custom_config.py'\n",
    "    custom_config_file_path_base = '/root/workspace/mmyolo/configs/yolox/yolox_s_fast_8xb8-300e_coco.py'  # Set your desired path\n",
    "\n",
    "    # Load the YOLOx config file\n",
    "    with open(dummy_config, 'r') as f:\n",
    "        cfg_content = f.read()\n",
    "\n",
    "    # Replace specific lines with new values\n",
    "    cfg_content = cfg_content.replace(\"data_root =\", f\"data_root = '{dataset_root}/'\")\n",
    "    cfg_content = cfg_content.replace(\"train_data_prefix =\", f\"train_data_prefix = '{images}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_data_prefix =\", f\"val_data_prefix = '{images}'\")\n",
    "    cfg_content = cfg_content.replace(\"train_ann_file =\", f\"train_ann_file = '{train_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_ann_file =\", f\"val_ann_file = '{val_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"num_classes =\", f\"num_classes = {NUM_CLASSES}\")\n",
    "    cfg_content = cfg_content.replace(\"meta_info =\", f\"meta_info = {metainfo}\")\n",
    "    cfg_content = cfg_content.replace(\"max_epochs =\", f\"max_epochs = {MAX_EPOCHS}\")\n",
    "    cfg_content = cfg_content.replace(\"train_batch_size_per_gpu =\", f\"train_batch_size_per_gpu = {BATCH_SIZE}\")\n",
    "\n",
    "    # Save the modified content to the new file\n",
    "    with open(custom_config_file_path_base, 'w') as custom_cfg_file:\n",
    "        custom_cfg_file.write(cfg_content)\n",
    "\n",
    "    print(f\"Custom config file has been created at {custom_config_file_path_base}.\")\n",
    "    print(\"dummy_config:\", dummy_config)\n",
    "    print(\"custom_config_file_path_base:\", custom_config_file_path_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bed28c-b4cb-4a35-b46d-81c339d32b88",
   "metadata": {},
   "source": [
    "# Yolov7 configuration setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e4441-bbff-466d-90ce-03bc6847797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model_type == 'YOLOv7':\n",
    "    dummy_config = '/root/workspace/mmyolo/configs/yolov7/custom_config.py'\n",
    "    custom_config_file_path_base = '/root/workspace/mmyolo/configs/yolov7/yolov7_l_syncbn_fast_8x16b-300e_coco.py'  # Set your desired path\n",
    "\n",
    "    # Load the YOLOx config file\n",
    "    with open(dummy_config, 'r') as f:\n",
    "        cfg_content = f.read()\n",
    "\n",
    "    # Replace specific lines with new values\n",
    "    cfg_content = cfg_content.replace(\"data_root =\", f\"data_root = '{dataset_root}/'\")\n",
    "    cfg_content = cfg_content.replace(\"train_data_prefix =\", f\"train_data_prefix = '{images}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_data_prefix =\", f\"val_data_prefix = '{images}'\")\n",
    "    cfg_content = cfg_content.replace(\"train_ann_file =\", f\"train_ann_file = '{train_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_ann_file =\", f\"val_ann_file = '{val_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"num_classes =\", f\"num_classes = {NUM_CLASSES}\")\n",
    "    cfg_content = cfg_content.replace(\"meta_info =\", f\"meta_info = {metainfo}\")\n",
    "    cfg_content = cfg_content.replace(\"max_epochs =\", f\"max_epochs = {MAX_EPOCHS}\")\n",
    "    cfg_content = cfg_content.replace(\"train_batch_size_per_gpu =\", f\"train_batch_size_per_gpu = {BATCH_SIZE}\")\n",
    "\n",
    "    # Save the modified content to the new file\n",
    "    with open(custom_config_file_path_base, 'w') as custom_cfg_file:\n",
    "        custom_cfg_file.write(cfg_content)\n",
    "\n",
    "    print(f\"Custom config file has been created at {custom_config_file_path_base}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01c3fc-88b1-4ec2-880e-ea31adf4284f",
   "metadata": {},
   "source": [
    "# Rtmdet configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981330f5-0a26-4c0e-813e-ee4cef295fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model_type == 'RTMDET':\n",
    "    dummy_config = '/root/workspace/mmyolo/configs/rtmdet/custom_config.py'\n",
    "    custom_config_file_path_base = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_l_syncbn_fast_8xb32-300e_coco.py'  # Set your desired path\n",
    "\n",
    "    # Load the YOLOx config file\n",
    "    with open(dummy_config, 'r') as f:\n",
    "        cfg_content = f.read()\n",
    "\n",
    "    # Replace specific lines with new values\n",
    "    cfg_content = cfg_content.replace(\"data_root =\", f\"data_root = '{dataset_root}/'\")\n",
    "    cfg_content = cfg_content.replace(\"train_data_prefix =\", f\"train_data_prefix = '{images}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_data_prefix =\", f\"val_data_prefix = '{images}'\")\n",
    "    cfg_content = cfg_content.replace(\"train_ann_file =\", f\"train_ann_file = '{train_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"val_ann_file =\", f\"val_ann_file = '{val_json_relpath}'\")\n",
    "    cfg_content = cfg_content.replace(\"num_classes =\", f\"num_classes = {NUM_CLASSES}\")\n",
    "    cfg_content = cfg_content.replace(\"meta_info =\", f\"meta_info = {metainfo}\")\n",
    "    cfg_content = cfg_content.replace(\"max_epochs =\", f\"max_epochs = {MAX_EPOCHS}\")\n",
    "    cfg_content = cfg_content.replace(\"train_batch_size_per_gpu =\", f\"train_batch_size_per_gpu = {BATCH_SIZE}\")\n",
    "\n",
    "    # Save the modified content to the new file\n",
    "    with open(custom_config_file_path_base, 'w') as custom_cfg_file:\n",
    "        custom_cfg_file.write(cfg_content)\n",
    "\n",
    "    print(f\"Custom config file has been created at {custom_config_file_path_base}.\")\n",
    "    print(\"dummy_config:\", dummy_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc427b9-d53a-46ca-b389-b560cdb76d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_model_variant=='yolox_tiny':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_tiny_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolox_s':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_s_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolox_m':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_m_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolox_l':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_l_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolox_x':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolox/yolox_x_fast_8xb8-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_tiny':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_tiny_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_l':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_l_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_x':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_x_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_w':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_w-p6_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'yolov7_e':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/yolov7/yolov7_e_syncbn_fast_8x16b-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_tiny':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_tiny_syncbn_fast_8xb32-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_s':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_s_syncbn_fast_8xb32-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_l':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_l_syncbn_fast_8xb32-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_m':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_m_syncbn_fast_8xb32-300e_coco.py'\n",
    "elif selected_model_variant == 'rtmdet_x':\n",
    "    config_file_path = '/root/workspace/mmyolo/configs/rtmdet/rtmdet_x_syncbn_fast_8xb32-300e_coco.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e7c1b-0e54-408e-a820-b0ce815eee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config_file_path=config_file_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983be65b-97e5-4a1b-b71f-5645356b78f0",
   "metadata": {},
   "source": [
    "# train the data with the selected model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15b54d-a7fa-4e47-8077-baae4ecd0cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/workspace/mmyolo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce68745-7330-4f09-80c3-b21b808b3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model_type=selected_model_type.lower()\n",
    "print(selected_model_type)\n",
    "custom_config_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846081d3-3908-44cc-8e80-f4d8575ea736",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75006f9-7aa4-4e13-b0d2-0eea214c6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Assuming config_file_path is something like \"yolox/config_file.py\"\n",
    "# config_file_path = config_file_path.split('/')[-1]\n",
    "command_line = f\"python tools/train.py configs/{selected_model_type}/{custom_config_file_path}\"\n",
    "\n",
    "# Run the command\n",
    "result = subprocess.run(command_line, shell=True)\n",
    "\n",
    "# Check the result\n",
    "if result.returncode == 0:\n",
    "    print(\"Command executed successfully\")\n",
    "else:\n",
    "    print(f\"Error executing the command. Return code: {result.returncode}\")\n",
    "    print(f\"Output: {result.stdout}\")\n",
    "    print(f\"Error: {result.stderr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a467bd3-538c-4157-a9e5-b606a0ee6eae",
   "metadata": {},
   "source": [
    "# testing with the trained model with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebf468-1b33-4f27-81ba-cec6279cd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Remove the last .py extension\n",
    "custom_config_file_path_without_extension = os.path.splitext(custom_config_file_path)[0]\n",
    "\n",
    "print(custom_config_file_path_without_extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44bbc9e-56f9-45fd-ba07-2bd8b180f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd7fd02-30cc-4662-b0da-266e1742a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427d975-1993-4add-8ae7-c36941559021",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_option == '1' and test_type == '0':\n",
    "    %cd /root/workspace/mmyolo\n",
    "    %run ./test.ipynb\n",
    "    testing_image(MAX_EPOCHS, custom_config_file_path_base,test_images,test_json_relpath,dummy_config,metainfo,BATCH_SIZE,NUM_CLASSES,dataset_root)   \n",
    "    %cd /root/workspace/mmyolo\n",
    "    import subprocess\n",
    "    command_line = f\"python tools/test.py \\\n",
    "        configs/{selected_model_type}/{custom_config_file_path} \\\n",
    "        work_dirs/{custom_config_file_path_without_extension}/epoch_{MAX_EPOCHS}.pth \\\n",
    "        --work-dir wk\"\n",
    "\n",
    "    # Run the command\n",
    "    result = subprocess.run(command_line, shell=True)\n",
    "\n",
    "    # Check the result\n",
    "    if result.returncode == 0:\n",
    "        print(\"Command executed successfully\")\n",
    "    else:\n",
    "        print(f\"Error executing the command. Return code: {result.returncode}\")\n",
    "        print(f\"Output: {result.stdout}\")\n",
    "        print(f\"Error: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c4ca3-1d63-4f86-ad8c-6ebc6e178617",
   "metadata": {},
   "source": [
    "# testing with the trained model with video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cdaab8-d3ba-402d-a51f-0d4b93f62e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_option == '1' and test_type == '1':\n",
    "    print(\".....testing on video......\")\n",
    "    %cd /root/workspace/mmyolo\n",
    "    %run ./test.ipynb\n",
    "    testing_video(MAX_EPOCHS, custom_config_file_path_base,selected_model_type,video_path,output_path,custom_config_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40a503-1f99-437c-8434-a365ef35df44",
   "metadata": {},
   "source": [
    "# Quantize the model (convert the pytorch model into tensorrt model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab195c-8aa4-4145-bd7b-2d0d6a229afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if quantize_option == '1':\n",
    "    %cd /root/workspace/mmyolo\n",
    "    %run ./quantize.ipynb\n",
    "    quantize(quantize_option, quantize_bits, batch_size_choice)\n",
    "    import subprocess\n",
    "    %cd /root/workspace/\n",
    "    command_line = f\"python mmdeploy/tools/deploy.py \\\n",
    "    /root/workspace/mmyolo/configs/deploy/detection_tensorrt_dynamic-192x192-960x960.py \\\n",
    "    {config_file_path} \\\n",
    "    mmyolo/work_dirs/{custom_config_file_path_without_extension}/epoch_{MAX_EPOCHS}.pth \\\n",
    "    mmyolo/demo/demo.jpg \\\n",
    "    --work-dir mmdeploy_model/{custom_config_file_path}_tensorrt \\\n",
    "    --device cuda \\\n",
    "    --dump-info\"\n",
    "\n",
    "    # Run the command\n",
    "    result = subprocess.run(command_line, shell=True)\n",
    "\n",
    "    # Check the result\n",
    "    if result.returncode == 0:\n",
    "        print(\"Command executed successfully\")\n",
    "    else:\n",
    "        print(f\"Error executing the command. Return code: {result.returncode}\")\n",
    "        print(f\"Output: {result.stdout}\")\n",
    "        print(f\"Error: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acc9e2-9126-4612-b188-684bf91c0682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42548165-5070-4363-946e-8a6df4759ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
